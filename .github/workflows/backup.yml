name: Back up my blog database

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Deploy even if no changes detected'
        required: false 
        type: boolean
  schedule:
    - cron: '26 */2 * * *'

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
    - name: Check out repo
      uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    - uses: actions/cache@v3
      name: Configure pip caching
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    - name: Install Python dependencies
      run: |
        pip install -r requirements.txt
    - name: Import Heroku DB into SQLite
      env:
        HEROKU_API_KEY: ${{ secrets.HEROKU_API_KEY }}
      run: |-
        db-to-sqlite \
          $(heroku config:get DATABASE_URL -a simonwillisonblog | sed s/postgres:/postgresql+psycopg2:/) \
          simonwillisonblog.db \
          --table auth_permission \
          --table auth_user \
          --table blog_blogmark \
          --table blog_blogmark_tags \
          --table blog_entry \
          --table blog_entry_tags \
          --table blog_quotation \
          --table blog_quotation_tags \
          --table blog_tag \
          --table blog_series \
          --table django_content_type \
          --table redirects_redirect
        sqlite-utils tables simonwillisonblog.db --counts --columns
    - name: Redact passwords
      run: |-
        sqlite-utils simonwillisonblog.db "update auth_user set password = null"
    - name: Remove un-interesting search_document columns
      run: |-
        sqlite-utils transform simonwillisonblog.db blog_blogmark --drop search_document
        sqlite-utils transform simonwillisonblog.db blog_entry --drop search_document
        sqlite-utils transform simonwillisonblog.db blog_quotation --drop search_document
    - name: Convert to newline-delimited JSON
      run: |-
        rm simonwillisonblog/* || true
        sqlite-diffable dump simonwillisonblog.db simonwillisonblog --all
    - name: Commit any changes
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add simonwillisonblog
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" || exit 0
        git push
        echo "::set-output name=change_detected::1"
  build_and_deploy:
    runs-on: ubuntu-latest
    needs: backup
    if: ${{ inputs.force_deploy || needs.backup.outputs.change_detected }}
    steps:
    - name: Check out repo
      uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    - uses: actions/cache@v3
      name: Configure pip caching
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    - name: Install Python dependencies
      run: |
        pip install -r requirements.txt
    - name: Restore previous database
      continue-on-error: true
      run: |-
        wget https://datasette.simonwillison.net/simonwillisonblog.db
    - name: Build database
      run: |-
        sqlite-diffable load simonwillisonblog.db simonwillisonblog --replace
        sqlite-utils tables simonwillisonblog.db --counts
    - name: Extract entities
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.COMPREHEND_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.COMPREHEND_SECRET_KEY }}
      run: |-
        pip install https://static.simonwillison.net/static/2022/sqlite_comprehend-0.1-py3-none-any.whl
        which sqlite-comprehend
        sqlite-comprehend --version
        sqlite-comprehend --help
        sqlite-comprehend entities --help
        sqlite-comprehend entities simonwillisonblog.db blog_entry title body --strip-tags
        sqlite-utils tables simonwillisonblog.db --counts
    - name: Configure FTS
      run: |-
        set +e
        sqlite-utils enable-fts simonwillisonblog.db blog_series title summary --create-triggers --tokenize porter 2>/dev/null
        sqlite-utils enable-fts simonwillisonblog.db blog_tag tag --create-triggers --tokenize porter 2>/dev/null
        sqlite-utils enable-fts simonwillisonblog.db blog_quotation quotation source --create-triggers --tokenize porter 2>/dev/null
        sqlite-utils enable-fts simonwillisonblog.db blog_entry title body --create-triggers --tokenize porter 2>/dev/null
        sqlite-utils enable-fts simonwillisonblog.db blog_blogmark link_title via_title commentary --create-triggers --tokenize porter 2>/dev/null
        set -e
    - name: Set up Cloud Run
      uses: google-github-actions/setup-gcloud@v0
      with:
        version: '275.0.0'
        service_account_email: ${{ secrets.GCP_SA_EMAIL }}
        service_account_key: ${{ secrets.GCP_SA_KEY }}
    - name: Deploy to Cloud Run
      run: |-
        gcloud config set run/region us-central1
        gcloud config set project datasette-222320
        datasette publish cloudrun simonwillisonblog.db \
          -m metadata.yml \
          --service simonwillisonblog \
          --install datasette-block-robots \
          --install datasette-graphql \
          --install datasette-search-all
