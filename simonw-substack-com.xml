<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" version="2.0">
  <channel>
    <title><![CDATA[Simon Willison’s Newsletter]]></title>
    <description><![CDATA[Web engineering, open source, data science, Datasette, SQLite, Python and more]]></description>
    <link>https://simonw.substack.com</link>
    <image>
      <url>https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsimonw.substack.com%2Fimg%2Fsubstack.png</url>
      <title>Simon Willison’s Newsletter</title>
      <link>https://simonw.substack.com</link>
    </image>
    <generator>Substack</generator>
    <lastBuildDate>Tue, 04 Apr 2023 16:32:44 GMT</lastBuildDate>
    <atom:link href="https://simonw.substack.com/feed" rel="self" type="application/rss+xml"/>
    <copyright><![CDATA[Simon Willison]]></copyright>
    <language><![CDATA[en]]></language>
    <webMaster><![CDATA[simonw@substack.com]]></webMaster>
    <itunes:owner>
      <itunes:email><![CDATA[simonw@substack.com]]></itunes:email>
      <itunes:name><![CDATA[Simon Willison]]></itunes:name>
    </itunes:owner>
    <itunes:author><![CDATA[Simon Willison]]></itunes:author>
    <googleplay:owner><![CDATA[simonw@substack.com]]></googleplay:owner>
    <googleplay:email><![CDATA[simonw@substack.com]]></googleplay:email>
    <googleplay:author><![CDATA[Simon Willison]]></googleplay:author>
    <item>
      <title><![CDATA[Think of language models like ChatGPT as a "calculator for words"]]></title>
      <description><![CDATA[Plus a podcast appearance]]></description>
      <link>https://simonw.substack.com/p/think-of-language-models-like-chatgpt</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/think-of-language-models-like-chatgpt</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Mon, 03 Apr 2023 16:30:01 GMT</pubDate>
      <enclosure url="https://substackcdn.com/image/youtube/w_728,c_limit/dGQ9q5WmWeE" length="0" type="image/jpeg"/>
      <content:encoded><![CDATA[<p>In this newsletter:</p><ul><li><p>Think of language models like ChatGPT as a "calculator for words"</p></li><li><p>What AI can do for you on the Theory of Change podcast</p></li></ul><p>Plus links and quotes from the past week.</p><h3><a href="https://simonwillison.net/2023/Apr/2/calculator-for-words/">Think of language models like ChatGPT as a "calculator for words"</a> - 2023-04-02</h3><p>One of the most pervasive mistakes I see people using with large language model tools like ChatGPT is trying to use them as a search engine.</p><p>As with <a href="https://simonwillison.net/series/llm-misconceptions/">other LLM misconceptions</a>, it's easy to understand why people do this.</p><p>If you ask an LLM a question, it will answer it - no matter what the question! Using them as an alternative to a search engine such as Google is one of the most obvious applications - and for a lot of queries this works just fine.</p><p>It's also going to quickly get you into trouble.</p><p>Ted Chiang's classic essay <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">ChatGPT Is a Blurry JPEG of the Web</a> helps explain why:</p><blockquote><p>Think of ChatGPT as a blurry jpeg of all the text on the Web. It retains much of the information on the Web, in the same way that a jpeg retains much of the information of a higher-resolution image, but, if you&#8217;re looking for an exact sequence of bits, you won&#8217;t find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it&#8217;s usually acceptable.</p></blockquote><p>The ChatGPT model is huge, but it's not huge enough to retain every exact fact it's encountered in its training set.</p><p>It can produce a convincing answer to anything, but that doesn't mean it's reflecting actual facts in its answers. You always have to stay skeptical and fact check what it tells you.</p><p>Language models are also famous for "hallucinating" - for inventing new facts that fit the sentence structure despite having no basis in the underlying data.</p><p>There are plenty of "facts" about the world which humans disagree on. Regular search lets you compare those versions and consider their sources. A language model might instead attempt to calculate some kind of average of every opinion it's been trained on - which is sometimes what you want, but often is not.</p><p>This becomes even more obvious when you consider smaller language models. <a href="https://simonwillison.net/2023/Mar/11/llama/">LLaMA 7B</a> can be represented as a 3.9 GB file - it contains an astonishing amount of information, but evidently that's not enough storage space to accurately answer every question you might have.</p><p>So if they're not reliable for use as a search engines, what are LLMs even good for?</p><h4>A calculator for words</h4><p>I like to think of language models like ChatGPT as a <strong>calculator for words</strong>.</p><p>This is reflected in their name: a "language model" implies that they are tools for working with language. That's what they've been trained to do, and it's language manipulation where they truly excel.</p><p>Want them to work with specific facts? Paste those into the language model as part of your original prompt!</p><p>There are so many applications of language models that fit into this calculator for words category:</p><ul><li><p>Summarization. Give them an essay and ask for a summary.</p></li><li><p>Question answering: given these paragraphs of text, answer this specific question about the information they represent.</p></li><li><p>Fact extraction: ask for bullet points showing the facts presented by an article.</p></li><li><p>Rewrites: reword things to be more "punchy" or "professional" or "sassy" or "sardonic" - part of the fun here is using increasingly varied adjectives and seeing what happens. They're very good with language after all!</p></li><li><p>Suggesting titles - actually a form of summarization.</p></li><li><p>World's most effective thesaurus. "I need a word that hints at X", "I'm very Y about this situation, what could I use for Y?" - that kind of thing.</p></li><li><p>Fun, creative, wild stuff. Rewrite this in the voice of a 17th century pirate. What would a sentient cheesecake think of this? How would Alexander Hamilton rebut this argument? Turn this into a rap battle. Illustrate this business advice with an anecdote about sea otters running a kayak rental shop. Write the script for kickstarter fundraising video about this idea.</p></li></ul><p>A calculator for words is an incredibly powerful thing.</p><h4>They can be hooked up to search engines</h4><p>Here's where things get a bit complicated: some language models CAN work as search engines. The two most obvious are Microsoft Bing and Google Bard, but there are plenty of other examples of this pattern too - there's even an alpha feature of ChatGPT called "browsing mode" that can do this.</p><p>You can think of these search tools as augmented language models.</p><p>The way these work is the language model identifies when a search might help answer a question... and then runs that search through an attached search engine, via an API.</p><p>It then copies data from the search results back into itself as part of an invisible prompt, and uses that new context to help it answer the original question.</p><p>It's effectively the same thing as if you ran a search, then copied and pasted information back into the language model and asked it a question about that data.</p><p>I wrote about how to implement this pattern against your own data in <a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/">How to implement Q&amp;A against your documentation with GPT3, embeddings and Datasette</a>. It's an increasingly common pattern.</p><p>It's important to note that there is still a risk of hallucination here, even when you feed it the facts you want it to use. I've caught both Bing and Bard adding made-up things in the middle of text that should have been entirely derived from their search results!</p><h4>Using language models effectively is deceptively difficult</h4><p>So many of the challenges involving language models come down to this: they look much, much easier to use than they actually are.</p><p>To get the most value out of them - and to avoid the many traps that they set for the unwary user - you need to spend time with them, and work to build an accurate mental model of how they work, what they are capable of and where they are most likely to go wrong.</p><p>I hope this "calculator for words" framing can help.</p><h4>A flaw in this analogy: calculators are repeatable</h4><p><a href="https://waxy.org/">Andy Baio</a> pointed out a flaw in this particular analogy: calculators always give you the same answer for a given input. Language models don't - if you run the same prompt through a LLM several times you'll get a slightly different reply every time.</p><p>This is a very good point! You should definitely keep this in mind.</p><p>All analogies are imperfect, but some are more imperfect that others.</p><div><hr></div><h3><a href="https://simonwillison.net/2023/Apr/2/what-ai-can-do-for-you/">What AI can do for you on Theory of Change</a> - 2023-04-02</h3><p>Matthew Sheffield invited me on his show <a href="https://flux.community/matthew-sheffield/2023/04/big-business-and-government-are-adopting-artificial-intelligence-what-can-it-do-for-the-rest-of-us/">Theory of Change</a> to talk about how AI models like ChatGPT, Bing and Bard work and practical applications of things you can do with them.</p><p>The episode is available <a href="https://soundcloud.com/theory-of-change-podcast/theory-of-change-066-simon-willison-on-what-chatgpt-and-ai-can-mean-for-you">on SoundCloud</a> and various podcast platforms (here's <a href="https://podcasts.apple.com/us/podcast/theory-of-change-066-simon-willison-on-technical/id1486920059?i=1000606913970">Apple Podcasts</a>), or you can <a href="https://www.youtube.com/watch?v=dGQ9q5WmWeE">watch it on YouTube</a>. I've also embedded the video below.</p><div id="youtube2-dGQ9q5WmWeE" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;dGQ9q5WmWeE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/dGQ9q5WmWeE?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><p>Our full conversation is nearly an hour and twenty minutes long! There's a <a href="https://flux.community/matthew-sheffield/2023/04/big-business-and-government-are-adopting-artificial-intelligence-what-can-it-do-for-the-rest-of-us/">transcript on the site</a> which includes additional links.</p><p>I'll quote one portion from towards the end of the interview, about ways to learn more about how to use these models:</p><blockquote><p>WILLISON: Websites pop up every day that claim to help you with AI, to be honest, at a rate that&#8217;s too far to even evaluate them and figure out which ones are good and which ones are snake oil. The thing that matters is actually interacting with these systems. You should be playing with Google Bard, and ChatGPT, and Microsoft Bing, and trying things out with a very skeptical approach.</p><p>Always assume that anything that it does, it could be making things up. It could be tricking you into thinking that it&#8217;s capable of something that it&#8217;s not. But that&#8217;s where you have to learn to experiment. You have to try different things, give it a URL, and then give it a broken URL and see how it differs between them.</p><p>Because that really is the most reliable way to get stuff done here. To sort of build that crucial mental model of what these things can do, and what they can&#8217;t. And it&#8217;s full of pitfalls. It&#8217;s so easy to fall into traps. So you do need to read around this stuff and find communities of people who are experimenting in it with, with you and, and so on.</p><p>Unfortunately, I don&#8217;t think there&#8217;s an easy answer to the question yet of how to learn to use these effectively, partly because ChatGPT isn&#8217;t even four months old yet. It&#8217;s four-month birthday&#8217;s on the 30th of March. All of this stuff is so new, we&#8217;re all figuring it out together. The key thing is, because it&#8217;s all so new, you need to hang out with other people.</p><p>You need to get involved with communities who are figuring this out. Share what you learn, see what other people learn, and basically try and help society as a whole come to terms with what these things even are and what we can do with them.</p><p>[...]</p><p>So that&#8217;s, I think, one of my sort of big personal ethical concerns is you should share your prompts. There are websites where you can sell prompts to people. No, no, no, no. Don&#8217;t do that. Share your prompts with other people. You get them to share the prompts back. We are all in this together. And sharing the prompts that work for you and the prompts that don&#8217;t is the fastest way that you can learn, and the fastest way that you can help other people learn as well.</p></blockquote><p>A shorter version of the above: <strong>share your prompts!</strong> We're all in this together. We have so much that we still need to figure out.</p><div><hr></div><p><strong>Link</strong> 2023-03-31 <a href="https://github.com/ggerganov/ggml/blob/master/examples/gpt-2/README.md#downloading-and-converting-the-original-models-cerebras-gpt">Downloading and converting the original models (Cerebras-GPT)</a>: Georgi Gerganov added support for the Apache 2 licensed Cerebras-GPT language model to his ggml C++ inference library, as used by llama.cpp.</p><div><hr></div><p><strong>Link</strong> 2023-03-31 <a href="https://oneusefulthing.substack.com/p/how-to-use-ai-to-do-practical-stuff">How to use AI to do practical stuff: A new guide</a>: Ethan Mollick's guide to practical usage of large language model chatbot like ChatGPT 3.5 and 4, Bing, Claude and Bard is the best I've seen so far. He includes useful warnings about common traps and things that these models are both useful for and useless at.</p><div><hr></div><p><strong>Quote</strong> 2023-03-31</p><blockquote><p><em>You&#8217;ll often find prompt engineers come from a history, philosophy, or English language background, because it&#8217;s wordplay. You're trying to distill the essence or meaning of something into a limited number of words.</em></p></blockquote><p><a href="https://www.bloomberg.com/news/articles/2023-03-29/ai-chatgpt-related-prompt-engineer-jobs-pay-up-to-335-000">Albert Phelps</a></p><div><hr></div><p><strong>Link</strong> 2023-04-01 <a href="https://github.com/davep/textual-mandelbrot">textual-mandelbrot</a>: I love this: run "pipx install textual-mandelbrot" and then "mandelexp" to get an interactive Mandelbrot fractal exploration interface right there in your terminal, built on top of Textual. The code for this is only 250 lines of Python and delightfully easy to follow.</p><div><hr></div><p><strong>Link</strong> 2023-04-02 <a href="https://ai-photo-sorter.vercel.app/">AI photo sorter</a>: Really interesting implementation of machine learning photo classification by Alexander Visheratin. This tool lets you select as many photos as you like from your own machine, then provides a web interface for classifying them into labels that you provide. It loads a 102MB quantized CLIP model and executes it in the browser using WebAssembly. Once classified, a "Generate script" button produces a copyable list of shell commands for moving your images into corresponding folders on your own machine. Your photos never get uploaded to a server - everything happens directly in your browser.</p><div><hr></div><p><strong>Link</strong> 2023-04-03 <a href="https://www.djangoproject.com/weblog/2023/apr/03/django-42-released/">Django 4.2 released</a>: "This version has been designated as a long-term support (LTS) release, which means that security and data loss fixes will be applied for at least the next three years." Some neat new async features, including improvements to async streaming responses.</p><div><hr></div><p><strong>Link</strong> 2023-04-03 <a href="https://arstechnica.com/tech-policy/2023/04/stable-diffusion-copyright-lawsuits-could-be-a-legal-earthquake-for-ai/">Stable Diffusion copyright lawsuits could be a legal earthquake for AI</a>: Timothy B. Lee provides a thorough discussion of the copyright lawsuits currently targeting Stable Diffusion and GitHub Copilot, including subtle points about how the interpretation of "fair use" might be applied to the new field of generative AI.</p><div><hr></div><p><strong>Quote</strong> 2023-04-03</p><blockquote><p><em>Beyond these specific legal arguments, Stability AI may find it has a &#8220;vibes&#8221; problem. The legal criteria for fair use are subjective and give judges some latitude in how to interpret them. And one factor that likely influences the thinking of judges is whether a defendant seems like a &#8220;good actor.&#8221; Google is a widely respected technology company that tends to win its copyright lawsuits. Edgier companies like Napster tend not to.</em></p></blockquote><p><a href="https://arstechnica.com/tech-policy/2023/04/stable-diffusion-copyright-lawsuits-could-be-a-legal-earthquake-for-ai/">Timothy B. Lee</a></p><div><hr></div>]]></content:encoded>
    </item>
    <item>
      <title><![CDATA[AI-enhanced development makes me more ambitious with my projects]]></title>
      <description><![CDATA[Using ChatGPT to build a system to archive ChatGPT messages]]></description>
      <link>https://simonw.substack.com/p/ai-enhanced-development-makes-me</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/ai-enhanced-development-makes-me</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Mon, 27 Mar 2023 21:46:14 GMT</pubDate>
      <enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg" length="0" type="image/jpeg"/>
      <content:encoded><![CDATA[<p>In this newsletter:</p><ul><li><p>AI-enhanced development makes me more ambitious with my projects</p></li></ul><p>Plus 6 links and 4 quotations</p><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3><a href="https://simonwillison.net/2023/Mar/27/ai-enhanced-development/">AI-enhanced development makes me more ambitious with my projects</a> - 2023-03-27</h3><p>The thing I'm most excited about in our weird new AI-enhanced reality is the way it allows me to be more <em>ambitious</em> with my projects.</p><p>As an experienced developer, ChatGPT (and GitHub Copilot) save me an enormous amount of "figuring things out" time. For everything from writing a for loop in Bash to remembering how to make a cross-domain CORS request in JavaScript - I don't need to even look things up any more, I can just prompt it and get the right answer 80% of the time.</p><p>This doesn't just make me more productive: it lowers my bar for when a project is worth investing time in at all.</p><p>In the past I've had plenty of ideas for projects which I've ruled out because they would take a day - or days, or weeks - of work to get to a point where they're useful. I have enough other stuff to build already!</p><p>But if ChatGPT can drop that down to an hour or less, those projects can suddenly become viable.</p><p>Which means I'm building all sorts of weird and interesting little things that previously I wouldn't have invested the time in.</p><p>I'll describe my latest one of these mini-projects in detail.</p><h4>Using ChatGPT to build a system to archive ChatGPT messages</h4><p>I use ChatGPT a lot, and I want my own archive of conversations I've had with it.</p><p>There's no API for retrieving previous conversations at the moment, but if you open up the browser DevTools and watch the network tab you can see it loading JSON any time you navigate to an older conversation.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg" width="1456" height="796" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:796,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;ChatGPT with the Chrome inspector open. On the left is a conversation, on the right the Chrome inspector is showing the underlying JSON that was fetched for that conversation in the Network pane.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="ChatGPT with the Chrome inspector open. On the left is a conversation, on the right the Chrome inspector is showing the underlying JSON that was fetched for that conversation in the Network pane." title="ChatGPT with the Chrome inspector open. On the left is a conversation, on the right the Chrome inspector is showing the underlying JSON that was fetched for that conversation in the Network pane." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6bd015f-f467-46a3-a968-9d2aad064569_2479x1356.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>This gave me an idea for a solution...</p><p>What if I could run some JavaScript on the ChatGPT site that grabbed that JSON data and sent it off to my own server?</p><p>I couldn't find the raw data in JavaScript variables available to the console, so I came up with an alternative approach: could I patch the default <code>fetch()</code> function to intercept calls made by the ChatGPT code to that endpoint, and intercept the data that way?</p><p>Normally this is where the project would end. Figuring out how to patch <code>fetch()</code> like that is non-trivial - where I'm using the software engineer's definition of "non-trivial" as meaning "I don't know how to do that off the top of my head". I'd have to do some thinking and research! I'm already tempted to drop this idea and work on something else.</p><p>But now I have ChatGPT... so I prompted it:</p><blockquote><p>Write a new JavaScript fetch() function which calls the old one but also saves the JSON that is retrieved - if it is used to retrieve JSON - in a window.fetchedData object</p></blockquote><p>It gave me some code, but it wasn't quite what I wanted. So I added a follow-up prompt:</p><blockquote><p>No I need to replace the old window.fetch() function entirely - I want to patch it so that I can intercept calls made by other existing code</p></blockquote><p>And it produced the following:</p><pre><code>// Define a global object to store fetched JSON data
window.fetchedData = {};

// Store a reference to the original fetch function
const originalFetch = window.fetch;

// Define a new fetch function that wraps the original fetch
window.fetch = async function(url, options) {
  try {
    // Call the original fetch function
    const response = await originalFetch(url, options);

    // Check if the response has a JSON content type
    const contentType = response.headers.get('content-type');
    if (contentType &amp;&amp; contentType.includes('application/json')) {
      // If the response is JSON, clone the response so we can read it twice
      const responseClone = response.clone();
      // Parse the JSON data and save it to the fetchedData object
      const jsonData = await responseClone.json();
      window.fetchedData[url] = jsonData;
    }

    // Return the original response
    return response;
  } catch (error) {
    // Handle any errors that occur during the fetch
    console.error('Error fetching and saving JSON:', error);
    throw error;
  }
};</code></pre><p>That's exactly what I wanted!</p><p>I pasted it into the DevTools console on the ChatGPT site and clicked on some links. It worked as intended.</p><p>Here's <a href="https://gist.github.com/simonw/8fbade64a3606645243b3438930b8159">that full ChatGPT transcript</a> that got me to this point.</p><p>So now I have a prototype! I've proved to myself that I can intercept the JSON data fetched by ChatGPT's own web application code.</p><p>I only wanted to run my code on requests that matched <code>https://chat.openai.com/backend-api/conversation/...</code> - I could write a regex for that, but I'd have to remember to escape the necessary characters. ChatGPT <a href="https://gist.github.com/simonw/103972b7eb0c1f45d536d0a0c04cb508">did that for me</a> too:</p><pre><code>const pattern = /^https:\/\/chat\.openai\.com\/backend-api\/conversation\//;</code></pre><p>So now I have the key building blocks I need for my solution: I can intercept JSON fetches and then filter to just the data from the endpoint I care about.</p><h4>But I need CORS support</h4><p>My plan was to have my intercepting <code>fetch()</code> call POST the JSON data to my own <a href="https://datsaette.cloud/">Datasette Cloud</a> instance, similar to how I record scraped Hacker News listings as described in <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">this post about Datasette's new write API</a>.</p><p>One big problem: this means that code running on the <code>chat.openai.com</code> domain needs to POST JSON to another server. And that means the other server needs to be serving <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS headers</a>.</p><p>Datasette Cloud doesn't (yet) support CORS - and I wasn't about to implement a new production feature there just so I could solve a problem for this prototype.</p><p>What I really needed was some kind of CORS proxy... a URL running somewhere which forwards traffic on to Datasette Cloud but adds CORS headers to enable it to be called from elsewhere.</p><p>This represents another potential blocking point: do I really want to implement an entire proxy web application just for this little project?</p><p>Here's my next ChatGPT prompt:</p><blockquote><p>Write a web app in python Starlette which has CORS enabled - including for the auth header - and forwards all incoming requests to any path to another server host specified in an environment variable</p></blockquote><p>I like <a href="https://www.starlette.io/">Starlette</a> and I know it has CORS support and is great for writing proxies. I was hopeful that GPT-4 had seen its documentation before the September 2021 cut-off date.</p><p>ChatGPT wrote me some very solid code! It used the <code>python-dotenv</code> package though, and I didn't feel like using that dependency. So I added:</p><blockquote><p>Rewrite that to use os.environ</p></blockquote><p>The exception handling looked wrong to me, so I said:</p><blockquote><p>Catch httpx.HTTPError as the only exception you care about</p></blockquote><p>And after just those three prompts it produced the following:</p><pre><code>import os
from starlette.applications import Starlette
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.routing import Route
from starlette.requests import Request
from starlette.responses import JSONResponse
import httpx

TARGET_SERVER_HOST = os.environ.get("TARGET_SERVER_HOST")

middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
]

app = Starlette(middleware=middleware)

async def forward_request(request: Request):
    try:
        async with httpx.AsyncClient() as client:
            target_url = f"{TARGET_SERVER_HOST}{request.url.path}"
            method = request.method
            headers = dict(request.headers)
            if "host" in headers:
                del headers["host"]
            if request.method in ["POST", "PUT", "PATCH"]:
                request_body = await request.json()
            else:
                request_body = None

            response = await client.request(
                method, target_url, headers=headers, json=request_body
            )
            return JSONResponse(response.json(), status_code=response.status_code)
    except httpx.HTTPError as e:
        return JSONResponse({"error": str(e)}, status_code=500)

app.add_route("/{path:path}", forward_request, methods=["GET", "POST", "PUT", "PATCH", "DELETE"])

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)</code></pre><p>I tested this locally... and spotted a bug. It would fail with a 500 error if the incoming request included a <code>content-length</code> header. I fixed that myself by adding this code:</p><pre><code>if "content-length" in headers:
    del headers["content-length"]</code></pre><p>My <a href="https://gist.github.com/simonw/e0a5368d8b465febefe6d4ae6f47f2da">finished code is here</a>. Here's <a href="https://gist.github.com/simonw/d95809e5a5c1441281cd5585270ab834">the ChatGPT transcript</a>.</p><p>I deployed this to Vercel using the method <a href="https://til.simonwillison.net/zeit-now/python-asgi-on-now-v2">described in this TIL</a> - and now I had a working proxy server.</p><h4>Creating the tables and a token</h4><p>ChatGPT had got me a long way. The rest of my implementation was now a small enough lift that I could quickly finish it by myself.</p><p>I created two tables in my Datasette Cloud instance by executing the following SQL (using the <a href="https://datasette.io/plugins/datasette-write">datasette-write</a> plugin):</p><pre><code>create table chatgpt_conversation (
  id text primary key,
  title text,
  create_time float,
  moderation_results text,
  current_node text,
  plugin_ids text
);
create table chatgpt_message (
  id text primary key,
  conversation_id text references chatgpt_conversation(id),
  author_role text,
  author_metadata text,
  create_time float,
  content text,
  end_turn integer,
  weight float,
  metadata text,
  recipient text
);</code></pre><p>Then I made myself a Datasette API token with permission to <code>insert-row</code> and <code>update-row</code> just for those two tables, using the new <a href="https://simonwillison.net/2022/Dec/15/datasette-1a2/#finely-grained-permissions">finely grained permissions feature</a> in the 1.0 alpha series.</p><p>The last step was to combine this all together into a <code>fetch()</code> function that did the right thing. I wrote this code by hand, using the ChatGPT prototype as a starting point:</p><pre><code>const TOKEN = "dstok_my-token-here";

// Store a reference to the original fetch function
window.originalFetch = window.fetch;

// Define a new fetch function that wraps the original fetch

window.fetch = async function (url, options) {
  try {
    // Call the original fetch function
    const response = await originalFetch(url, options);

    // Check if the response has a JSON content type
    const contentType = response.headers.get("content-type");
    if (contentType &amp;&amp; contentType.includes("application/json")) {
      // If the response is JSON, clone the response so we can read it twice
      const responseClone = response.clone();
      // Parse the JSON data and save it to the fetchedData object
      const jsonData = await responseClone.json();
      // NOW: if url for https://chat.openai.com/backend-api/conversation/...
      // do something very special with it
      const pattern =
        /^https:\/\/chat\.openai\.com\/backend-api\/conversation\/(.*)/;
      const match = url.match(pattern);
      if (match) {
        const conversationId = match[1];
        console.log("conversationId", conversationId);
        console.log("jsonData", jsonData);
        const conversation = {
          id: conversationId,
          title: jsonData.title,
          create_time: jsonData.create_time,
          moderation_results: JSON.stringify(jsonData.moderation_results),
          current_node: jsonData.current_node,
          plugin_ids: JSON.stringify(jsonData.plugin_ids),
        };
        fetch(
          "https://starlette-cors-proxy-simonw-datasette.vercel.app/data/chatgpt_conversation/-/insert",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${TOKEN}`,
            },
            mode: "cors",
            body: JSON.stringify({
              row: conversation,
              replace: true,
            }),
          }
        )
          .then((d) =&gt; d.json())
          .then((d) =&gt; console.log("d", d));
        const messages = Object.values(jsonData.mapping)
          .filter((m) =&gt; m.message)
          .map((message) =&gt; {
            m = message.message;
            let content = "";
            if (m.content) {
              if (m.content.text) {
                content = m.content.text;
              } else {
                content = m.content.parts.join("\n");
              }
            }
            return {
              id: m.id,
              conversation_id: conversationId,
              author_role: m.author ? m.author.role : null,
              author_metadata: JSON.stringify(
                m.author ? m.author.metadata : {}
              ),
              create_time: m.create_time,
              content: content,
              end_turn: m.end_turn,
              weight: m.weight,
              metadata: JSON.stringify(m.metadata),
              recipient: m.recipient,
            };
          });
        fetch(
          "https://starlette-cors-proxy-simonw-datasette.vercel.app/data/chatgpt_message/-/insert",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${TOKEN}`,
            },
            mode: "cors",
            body: JSON.stringify({
              rows: messages,
              replace: true,
            }),
          }
        )
          .then((d) =&gt; d.json())
          .then((d) =&gt; console.log("d", d));
      }
    }

    // Return the original response
    return response;
  } catch (error) {
    // Handle any errors that occur during the fetch
    console.error("Error fetching and saving JSON:", error);
    throw error;
  }
};</code></pre><p>The fiddly bit here was writing the JavaScript that reshaped the ChatGPT JSON into the <code>rows: [array-of-objects]</code> format needed by the <a href="https://docs.datasette.io/en/1.0a2/json_api.html#the-json-write-api">Datasette JSON APIs</a>. I could probably have gotten ChatGPT to help with that - but in this case I pasted the SQL schema into a comment and let GitHub Copilot auto-complete parts of the JavaScript for me as I typed it.</p><h4>And it works</h4><p>Now I can paste the above block of code into the browser console on <code>chat.openai.com</code> and any time I click on one of my older conversations in the sidebar the <code>fetch()</code> will be intercepted and the JSON data will be saved to my Datasette Cloud instance.</p><h4>A public demo</h4><p>I've set up a public demo exposing messages from selected conversations here:</p><p><a href="https://simon.datasette.cloud/data/chatgpt_public_messages?_facet=conversation">simon.datasette.cloud/data/chatgpt_public_messages</a></p><p>The demo itself is powered by an extra table (listing the conversations that should be public) and a SQL view.</p><p>I used the <code>datasette-write</code> plugin again to create these:</p><pre><code>create table chatgpt_public (id text primary key);

create view chatgpt_public_messages as select
  chatgpt_message.id,
  chatgpt_conversation.title || char(10) || chatgpt_conversation.id as conversation,
  chatgpt_message.author_role,
  chatgpt_message.content,
  datetime(chatgpt_message.create_time, 'unixepoch') as create_time
from
  chatgpt_message join chatgpt_conversation on conversation_id = chatgpt_conversation.id
where
  chatgpt_message.create_time is not null
  and conversation_id in (select id from chatgpt_public)
order by
  chatgpt_message.create_time</code></pre><p>Then I set the <code>chatgpt_public_messages</code> view to be public (using <a href="https://datasette.io/plugins/datasette-public">datasette-public</a>).</p><p>Now I can insert conversation IDs into that <code>chatgpt_public</code> table to expose their messages in the public view.</p><p>This is the first time I've used a SQL view like this to selectively publish data from a private larger table, and I think it's a really neat pattern. I'd like to make it easier to do without writing custom SQL though!</p><h4>It's a lot more than just this project</h4><p>This ChatGPT archiving problem is just one example from the past few months of things I've built that I wouldn't have tackled without AI-assistance.</p><p>It took me longer to write this up than it did to implement the entire project from start to finish!</p><p>When evaluating if a new technology is worth learning and adopting, I have two criteria:</p><ol><li><p>Does this let me build things that would have been impossible to build without it?</p></li><li><p>Can this reduce the effort required for some projects such that they tip over from "not worth it" to "worth it" and I end up building them?</p></li></ol><p>Large language models like GPT3/4/LLaMA/Claude etc clearly meet both of those criteria - and their impact on point two keeps on getting stronger for me.</p><h4>Some more examples</h4><p>Here are a few more examples of projects I've worked on recently that wouldn't have happened without at least some level of AI assistance:</p><ul><li><p>I used ChatGPT to <a href="https://simonwillison.net/2023/Mar/24/datasette-chatgpt-plugin/">generate me the OpenAI schema</a> I needed to build the <a href="https://datasette.io/plugins/datasette-chatgpt-plugin">datasette-chatgpt-plugin</a> plugin, allowing human language questions in ChatGPT to be answered by SQL queries executed against Datasette.</p></li><li><p><a href="https://til.simonwillison.net/gpt3/chatgpt-applescript">Using ChatGPT to write AppleScript</a> describes how I used ChatGPT to finally figure out enough AppleScript to liberate my notes data, resulting in building <a href="https://datasette.io/tools/apple-script-to-sqlite">apple-note-to-sqlite</a>.</p></li><li><p><code>datasette-paste-table</code> isn't in a usable state yet, but I built the first interactive prototype for that <a href="https://github.com/simonw/datasette-paste-table/issues/1">using ChatGPT</a>.</p></li><li><p><a href="https://til.simonwillison.net/jq/git-log-json">Convert git log output to JSON using jq</a> is something I figured out using ChatGPT - <a href="https://gist.github.com/simonw/c3b486fa90d7c32a0e8dfb47e151090a">transcript here</a>.</p></li><li><p><a href="https://simonwillison.net/2022/Dec/5/rust-chatgpt-copilot/">Learning Rust with ChatGPT, Copilot and Advent of Code</a> describes one of my earlier efforts to use ChatGPT to help learn a completely new (to me) programming language.</p></li></ul><div><hr></div><p><strong>Link</strong> 2023-03-24 <a href="https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html">Hello Dolly: Democratizing the magic of ChatGPT with open models</a>: A team at DataBricks applied the same fine-tuning data used by Stanford Alpaca against LLaMA to a much older model - EleutherAI's GPT-J 6B, first released in May 2021. As with Alpaca, they found that instruction tuning took the raw model - which was extremely difficult to interact with - and turned it into something that felt a lot more like ChatGPT. It's a shame they reused the license-encumbered 52,000 training samples from Alpaca, but I doubt it will be long before someone recreates a freely licensed alternative to that training set.</p><div><hr></div><p><strong>Quote</strong> 2023-03-24</p><blockquote><p><em>SvelteKit is written in JS and distributed as source code &#8212; no build step &#8212; and it's been miraculous for productivity. build steps make sense for apps, they make much less sense for libraries</em></p></blockquote><p><a href="https://twitter.com/rich_harris/status/1639344836766576640">Rich Harris</a></p><div><hr></div><p><strong>Link</strong> 2023-03-26 <a href="https://jamesturk.github.io/scrapeghost/">scrapeghost</a>: Scraping is a really interesting application for large language model tools like GPT3. James Turk's scrapeghost is a very neatly designed entrant into this space - it's a Python library and CLI tool that can be pointed at any URL and given a roughly defined schema (using a neat mini schema language) which will then use GPT3 to scrape the page and try to return the results in the supplied format.</p><div><hr></div><p><strong>Quote</strong> 2023-03-26</p><blockquote><p><em>After three decades of working with software, I'm also seeing myself learning faster using ChatGPT. So apparently it works even for us more seasoned programmers.</em></p></blockquote><p><a href="https://twitter.com/antirez/status/1639692376779128833">Salvatore Sanfilippo</a></p><div><hr></div><p><strong>Link</strong> 2023-03-26 <a href="https://en.wikipedia.org/wiki/Leicester_balloon_riot">Leicester balloon riot</a>: In 1864 a test flight of a new hydrogen balloon in Leicester's Victoria Park attracted 50,000 spectators, and ended in a riot that destroyed the balloon. "Early in the afternoon there was a disturbance when a gentleman, claiming to be an aeronaut, announced that Britannia was not Coxwell's newest and biggest balloon but an older model. This enraged the crowd who, shortly after 2pm, broke down the barrier and demanded that Coxwell take off immediately."</p><div><hr></div><p><strong>Link</strong> 2023-03-27 <a href="https://www.reddit.com/r/blender/comments/121lhfq/i_lost_everything_that_made_me_love_my_job/">I lost everything that made me love my job through Midjourney over night</a>: A poster on r/blender describes how their job creating graphics for mobile games has switched from creating 3D models for rendering 2D art to prompting Midjourney v5 and cleaning up the results in Photoshop. "I am now able to create, rig and animate a character thats spit out from MJ in 2-3 days. Before, it took us several weeks in 3D. [...] I always was very sure I wouldn&#8217;t lose my job, because I produce slightly better quality. This advantage is gone, and so is my hope for using my own creative energy to create."</p><div><hr></div><p><strong>Quote</strong> 2023-03-27</p><blockquote><p><em>I think it&#8217;s likely that soon all computer users will have the ability to develop small software tools from scratch, and to describe modifications they&#8217;d like made to software they&#8217;re already using.</em></p></blockquote><p><a href="https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming.html">Geoffrey Litt</a></p><div><hr></div><p><strong>Quote</strong> 2023-03-27</p><blockquote><p><em>Every wave of technological innovation has been unleashed by something costly becoming cheap enough to waste. Software production has been too complex and expensive for too long, which has caused us to underproduce software for decades, resulting in immense, society-wide technical debt. This technical debt is about to contract in a dramatic, economy-wide fashion as the cost and complexity of software production collapses, releasing a wave of innovation.</em></p></blockquote><p><a href="https://skventures.substack.com/p/societys-technical-debt-and-softwares">Paul Kedrosky and Eric Norlin</a></p><div><hr></div><p><strong>Link</strong> 2023-03-27 <a href="https://simple-push-demo.vercel.app/">Simple Push Demo</a>: Safari 16.4 is out (upgrade to iOS 16.4 to get it) and the biggest feature for me is mobile support for Web Push notifications. This little demo tool was the first I found that successfully sent a notification to my phone: frustratingly you have to add it to your home page first in order to enable the feature. The site also provides a curl command for sending push notifications through the Apple push server once a token has been registered, which is the crucial step to figuring out how to build applications that can send out notifications to users who have registered to receive them.</p><div><hr></div><p><strong>Link</strong> 2023-03-27 <a href="https://twitter.com/ggerganov/status/1640416314773700608">LLaMA voice chat, with Whisper and Siri TTS</a>. llama.cpp author Georgi Gerganov has stitched together the LLaMA language model, the Whisper voice to text model (with his whisper.cpp library) and the macOS &#8220;say&#8221; command to create an entirely offline AI agent that he can talk to with his voice and that can speak replies straight back to him.</p><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div>]]></content:encoded>
    </item>
    <item>
      <title><![CDATA[I built a ChatGPT plugin to answer questions about data hosted in Datasette]]></title>
      <description><![CDATA[Plus: Don't trust AI to talk accurately about itself]]></description>
      <link>https://simonw.substack.com/p/i-built-a-chatgpt-plugin-to-answer</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/i-built-a-chatgpt-plugin-to-answer</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Fri, 24 Mar 2023 21:13:01 GMT</pubDate>
      <enclosure url="https://substackcdn.com/image/youtube/w_728,c_limit/MKbLUb8RaGs" length="0" type="image/jpeg"/>
      <content:encoded><![CDATA[<p>In this newsletter:</p><ul><li><p>I built a ChatGPT plugin to answer questions about data hosted in Datasette</p></li><li><p>Don't trust AI to talk accurately about itself: Bard wasn't trained on Gmail</p></li><li><p>Weeknotes: AI won't slow down, a new newsletter and a huge Datasette refactor</p></li></ul><p>Plus 12 links and 4 quotations</p><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3><a href="https://simonwillison.net/2023/Mar/24/datasette-chatgpt-plugin/">I built a ChatGPT plugin to answer questions about data hosted in Datasette</a> - 2023-03-24</h3><p>Yesterday OpenAI announced support for <a href="https://openai.com/blog/chatgpt-plugins">ChatGPT plugins</a>. It's now possible to teach ChatGPT how to make calls out to external APIs and use the responses to help generate further answers in the current conversation.</p><p>My open source project <a href="https://datasette.io/">Datasette</a> makes it easy to host data online, and already provides a JSON API for executing SQLite queries.</p><p>I know from past experiments that GPT3/4 are able to construct SQLite-compatible SQL queries. I figured that Datasette and ChatGPT would be a perfect combination.</p><p>Datasette itself has <a href="https://datasette.io/plugins">a plugin system</a> which can be used to add new features, including the new URL routes needed by the <a href="https://platform.openai.com/docs/plugins/getting-started">ChatGPT plugin specification</a>.</p><p>So I built <a href="https://datasette.io/plugins/datasette-chatgpt-plugin">datasette-chatgpt-plugin</a> - a Datasette plugin that turns a Datasette instance into a ChatGPT plugin, and allows you to ask questions of your own data directly from ChatGPT.</p><h4>datasette-chatgpt-plugin</h4><p>The new plugin can be installed using <code>datasette install datasette-chatgpt-plugin</code>. It's only useful if it's deployed online though, since ChatGPT needs to be able to access it.</p><p>I'm running it on the official <a href="https://datasette.io/">datasette.io website</a> - which is itself <a href="https://simonwillison.net/2021/Jul/28/baked-data/">a customized instance of Datasette</a>. The plugin provides access to the <a href="https://datasette.io/content">datasette.io/content</a> database, which has tables for things like Datasette news, releases and available plugins.</p><p>Here's <a href="https://www.youtube.com/watch?v=MKbLUb8RaGs">a video demo</a> showing some of the things ChatGPT can do with the plugin installed.</p><div id="youtube2-MKbLUb8RaGs" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;MKbLUb8RaGs&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/MKbLUb8RaGs?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><p>I've only just got this working, but here's a query that illustrates how effective it can be. I asked:</p><blockquote><p>What are the most popular plugins?</p></blockquote><p>It gave me back the following:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg" width="1448" height="1766" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1766,&quot;width&quot;:1448,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Prompt: What are the most popular plugins? ChatGPT said: Used Query datasette.io UNVERIFIED. Here are the most popular Datasette plugins based on the number of GitHub stars: 1. Plugin: datasette-dashboards GitHub Repository: clement/datasette-dashboards GitHub Stars: 84 2. Plugin: dogsheep-beta GitHub Repository: dogsheep/dogsheep-beta GitHub Stars: 78 3. Plugin: datasette-graphql GitHub Repository: simonw/datasette-graphql GitHub Stars: 75 4. Plugin: datasette-ripgrep GitHub Repository: simonw/datasette-ripgre GitHub Stars: 63 5. Plugin: datasette-scraper GitHub Repository: cldellow/datasette-scraper GitHub Stars: 44 These are the top 5 most popular Datasette plugins based on the number of stars they have received on GitHub. If you have any other questions or need more information, please let me know! There follows a gallery of thumbnails of those links.&quot;,&quot;title&quot;:&quot;Prompt: What are the most popular plugins? ChatGPT said: Used Query datasette.io UNVERIFIED. Here are the most popular Datasette plugins based on the number of GitHub stars: 1. Plugin: datasette-dashboards GitHub Repository: clement/datasette-dashboards GitHub Stars: 84 2. Plugin: dogsheep-beta GitHub Repository: dogsheep/dogsheep-beta GitHub Stars: 78 3. Plugin: datasette-graphql GitHub Repository: simonw/datasette-graphql GitHub Stars: 75 4. Plugin: datasette-ripgrep GitHub Repository: simonw/datasette-ripgre GitHub Stars: 63 5. Plugin: datasette-scraper GitHub Repository: cldellow/datasette-scraper GitHub Stars: 44 These are the top 5 most popular Datasette plugins based on the number of stars they have received on GitHub. If you have any other questions or need more information, please let me know! There follows a gallery of thumbnails of those links.&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Prompt: What are the most popular plugins? ChatGPT said: Used Query datasette.io UNVERIFIED. Here are the most popular Datasette plugins based on the number of GitHub stars: 1. Plugin: datasette-dashboards GitHub Repository: clement/datasette-dashboards GitHub Stars: 84 2. Plugin: dogsheep-beta GitHub Repository: dogsheep/dogsheep-beta GitHub Stars: 78 3. Plugin: datasette-graphql GitHub Repository: simonw/datasette-graphql GitHub Stars: 75 4. Plugin: datasette-ripgrep GitHub Repository: simonw/datasette-ripgre GitHub Stars: 63 5. Plugin: datasette-scraper GitHub Repository: cldellow/datasette-scraper GitHub Stars: 44 These are the top 5 most popular Datasette plugins based on the number of stars they have received on GitHub. If you have any other questions or need more information, please let me know! There follows a gallery of thumbnails of those links." title="Prompt: What are the most popular plugins? ChatGPT said: Used Query datasette.io UNVERIFIED. Here are the most popular Datasette plugins based on the number of GitHub stars: 1. Plugin: datasette-dashboards GitHub Repository: clement/datasette-dashboards GitHub Stars: 84 2. Plugin: dogsheep-beta GitHub Repository: dogsheep/dogsheep-beta GitHub Stars: 78 3. Plugin: datasette-graphql GitHub Repository: simonw/datasette-graphql GitHub Stars: 75 4. Plugin: datasette-ripgrep GitHub Repository: simonw/datasette-ripgre GitHub Stars: 63 5. Plugin: datasette-scraper GitHub Repository: cldellow/datasette-scraper GitHub Stars: 44 These are the top 5 most popular Datasette plugins based on the number of stars they have received on GitHub. If you have any other questions or need more information, please let me know! There follows a gallery of thumbnails of those links." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f8e246-0ca2-4ef1-a8ce-1517673dae63_1448x1766.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>Clicking the little arrow next to "Used query datasette.io" reveals the API call it made, exposing the SQL query it generated:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg" width="1456" height="1322" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1322,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Used query datasette.io expanded - shows JSON for the query and the returned response&quot;,&quot;title&quot;:&quot;Used query datasette.io expanded - shows JSON for the query and the returned response&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Used query datasette.io expanded - shows JSON for the query and the returned response" title="Used query datasette.io expanded - shows JSON for the query and the returned response" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0afdd9d3-2a6b-4422-9a00-290d15a0ffae_1476x1340.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>The API call it made was:</p><pre><code><code>{
  "sql": "SELECT name, full_name, stargazers_count FROM plugins ORDER BY stargazers_count DESC LIMIT 5",
  "_shape": "array"
}</code></code></pre><p>You can <a href="https://datasette.io/content?sql=SELECT%20name%2C%20full_name%2C%20stargazers_count%20FROM%20plugins%20ORDER%20BY%20stargazers_count%20DESC%20LIMIT%205">try that query in Datasette here</a> - or <a href="https://datasette.io/content.json?sql=SELECT%20name%2C%20full_name%2C%20stargazers_count%20FROM%20plugins%20ORDER%20BY%20stargazers_count%20DESC%20LIMIT%205&amp;_shape=array">here's the JSON version</a>.</p><p>Here's the JSON that was returned:</p><pre><code><code>[
  {
    "name": "datasette-dashboards",
    "full_name": "rclement/datasette-dashboards",
    "stargazers_count": 84
  },
  {
    "name": "dogsheep-beta",
    "full_name": "dogsheep/dogsheep-beta",
    "stargazers_count": 78
  },
  {
    "name": "datasette-graphql",
    "full_name": "simonw/datasette-graphql",
    "stargazers_count": 75
  },
  {
    "name": "datasette-ripgrep",
    "full_name": "simonw/datasette-ripgrep",
    "stargazers_count": 63
  },
  {
    "name": "datasette-scraper",
    "full_name": "cldellow/datasette-scraper",
    "stargazers_count": 44
  }
]</code></code></pre><p>ChatGPT turns the JSON into a nice human-readable reply. It also knows how to generate thumbnails from <code>og:image</code> metadata, adding a gallery of those to the end of the reply.</p><h4>How the plugin works</h4><p>Building ChatGPT plugins, like so much involving Large Language Models, is both really easy and deceptively complicated.</p><p>You give ChatGPT a short, human-ish language description of your plugin and how to use it, and a machine-readable OpenAPI schema with the details of the API.</p><p>And that's it! The language model figures out everything else.</p><p>Datasette exposes a JSON API that speaks SQL. ChatGPT knows SQL already, so all my prompt needed to do was give it some hints - in particular tell it to use the SQLite dialect.</p><p>Here's the prompt I'm using at the moment:</p><blockquote><p>Run SQLite queries against a database hosted by Datasette. Datasette supports most SQLite syntax but does not support PRAGMA statements. Use <code>select group_concat(sql, ';') from sqlite_master</code> to see the list of tables and their columns Use <code>select sql from sqlite_master where name = 'table_name'</code> to see the schema for a table, including its columns. Instead of <code>PRAGMA table_info(table_name)</code> use <code>select * from pragma_table_info('table_name')</code>. PRAGMA statements are not allowed. <code>select * from pragma_table_info('table_name')</code> is allowed.</p></blockquote><p>In my early experiments it kept trying to run <code>PRAGMA table_info()</code>, hence my increasingly frustrated prompts about that!</p><p>With hindsight, I don't think it was re-fetching my prompt while I was developing the plugin, so those repeated warnings probably aren't needed.</p><p>Your application needs to serve two additional pages - a plugin description at <code>/.well-known/ai-plugin.json</code> and an OpenAI schema linked to by that description.</p><p>You can see those two pages for my <code>datasette.io</code> deployment here:</p><ul><li><p><a href="https://datasette.io/.well-known/ai-plugin.json">https://datasette.io/.well-known/ai-plugin.json</a></p></li><li><p><a href="https://datasette.io/-/chatgpt-openapi-schema.yml">https://datasette.io/-/chatgpt-openapi-schema.yml</a></p></li></ul><p>The <code>ai-plugin.json</code> file currently looks like this:</p><pre><code><code>{
  "schema_version": "v1",
  "name_for_model": "datasette_datasette_io_3c330f",
  "name_for_human": "Query datasette.io",
  "description_for_model": "Run SQLite queries against a database hosted by Datasette.\nDatasette supports most SQLite syntax but does not support PRAGMA statements.\nUse `select group_concat(sql, ';') from sqlite_master` to see the list of tables and their columns\nUse `select sql from sqlite_master where name = 'table_name'` to see the schema for a table, including its columns.\nInstead of `PRAGMA table_info(table_name)` use `select * from pragma_table_info('table_name')`\nPRAGMA statements are not allowed. `select * from pragma_table_info('table_name') is allowed.",
  "description_for_human": "Run SQL against data in Datasette.",
  "auth": {
    "type": "none"
  },
  "api": {
    "type": "openapi",
    "url": "https://datasette.io/-/chatgpt-openapi-schema.yml",
    "has_user_authentication": false
  },
  "logo_url": "https://avatars.githubusercontent.com/u/126964132?s=400&amp;u=08b2ed680144a4feb421308f09e5f3cc5876211a&amp;v=4",
  "contact_email": "hello@contact.com",
  "legal_info_url": "hello@legal.com"
}</code></code></pre><p>And the <code>chatgpt-openapi-schema.yml</code> file contains this:</p><pre><code><code>openapi: 3.0.1
info:
  title: Datasette API
  description: Execute SQL queries against a Datasette database and return the results as JSON
  version: 'v1'
servers:
  - url: https://datasette.io
paths:
  /content.json:
    get:
      operationId: query
      summary: Execute a SQLite SQL query against the content database
      description: Accepts SQLite SQL query, returns JSON. Does not allow PRAGMA statements.
      parameters:
      - name: sql
        in: query
        description: The SQL query to be executed
        required: true
        schema:
          type: string
      - name: _shape
        in: query
        description: The shape of the response data. Must be "array"
        required: true
        schema:
          type: string
          enum:
            - array
      responses:
        '200':
          description: Successful SQL results
          content:
            application/json:
              schema:
                type: array
                items:
                  type: object
        '400':
          description: Bad request
        '500':
          description: Internal server error</code></code></pre><p>I haven't actually used OpenAPI schemas before... so I got ChatGPT to write the initial version for me, using the following prompt:</p><blockquote><p>Write an OpenAPI schema explaining the <a href="https://latest.datasette.io/fixtures.json?sql=select+*+from+facetable&amp;_shape=array">https://latest.datasette.io/fixtures.json?sql=select+*+from+facetable&amp;_shape=array</a> GET API which accepts SQL and returns an array of JSON objects</p></blockquote><p>For a detailed account of how I built the plugin, take a look at my notes in <a href="https://github.com/simonw/datasette-chatgpt-plugin/issues/1">issue #1</a> in the repository.</p><p>I prototyped the initial plugin using <a href="https://glitch.com/">Glitch</a>, because that's the fastest way I know to get a live-on-the-web application which constantly reflects new changes to the code. This made iterating much faster... on the OpenAPI schema at least. As far as I can tell ChatGPT only loads that <code>ai-plugin.json</code> file once, which is frustrating because it means you have to deploy a new copy of the application to get it to re-read that crucial prompt.</p><p>I ended up doing most of my prompt engineering in ChatGPT itself though - I could tell it "Instead of <code>PRAGMA table_info(table_name)</code> use <code>select * from pragma_table_info('table_name')</code>" and then re-try my previous question to see if the new instruction fixed any problems I was having.</p><h4>The bad news: it can hallucinate</h4><p>Here's the bad news. I've been playing with this for only a short time, so I'm still exploring its abilities. I've already had a couple of instances of it hallucinating answers <em>despite</em> having looked them up in the database first.</p><p>I'm hoping I can address this somewhat with further prompt engineering - "only use information returned from the query to answer the question" kind of stuff. But I can't guarantee I'll be able to suppress this entirely, which for a database querying tool is an extremely serious problem.</p><p>More about this, including some examples, in <a href="https://github.com/simonw/datasette-chatgpt-plugin/issues/2">issue #2</a> in the repo.</p><h4>Want to try this with your own data?</h4><p>The ChatGPT plugin system isn't available outside of the preview yet, but when it is I'll be adding this functionality to my <a href="https://datasette.cloud/">Datasette Cloud</a> SaaS platform, for people who don't want to install and run Datasette themselves.</p><p>You can <a href="https://www.datasette.cloud/preview/">sign up for the Datasette Cloud preview here</a> if you'd like to learn more.</p><h4>Previous experiments</h4><p>I've experimented with variants of this pattern myself before: it turns out it's surprisingly easy to enhance the capabilities of a large language model by providing it access to additional tools. Here's some previous work:</p><ul><li><p><a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/">How to implement Q&amp;A against your documentation with GPT3, embeddings and Datasette</a> describes a pattern of searching an existing corpus for relevant information and appending that to the prompt in order to answer a user's question.</p></li><li><p><a href="https://til.simonwillison.net/llms/python-react-pattern">A simple Python implementation of the ReAct pattern for LLMs</a> shows a more advanced pattern, similar to the new ChatGPT plugins mechanism, where multiple tools can be registered with the model and used to generate responses. It's based on the paper <a href="https://react-lm.github.io/">ReAct: Synergizing Reasoning and Acting in Language Models</a>.</p></li></ul><p><strong>Quote</strong> 2023-03-21</p><blockquote><p><em>Was on a plane yesterday, studying some physics; got confused about something and I was able to solve my problem by just asking alpaca-13B&#8212;running locally on my machine&#8212;for an explanation. Felt straight-up spooky.</em></p></blockquote><p><a href="https://twitter.com/andy_matuschak/status/1638006360096018432">Andy Matuschak</a></p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://news.ycombinator.com/item?id=35242069">OpenAI to discontinue support for the Codex API</a>: OpenAI shutting off access to their Codex model - a GPT3 variant fine-tuned for code related tasks, but that was being used for all sorts of other purposes - partly because it had been in a beta phase for over a year where OpenAI didn't charge anything for it. This feels to me like a major strategic misstep for OpenAI: they're only giving three days notice, which is shaking people's confidence in them as a stable platform for building on at the very moment when competition from other vendors (and open source alternatives) is heating up.</p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://www.theverge.com/2023/3/21/23648315/adobe-firefly-ai-image-generator-announced">Adobe made an AI image generator &#8212; and says it didn&#8217;t steal artists&#8217; work to do it</a>: Adobe Firefly is a brand new text-to-image model which Adobe claim was trained entirely on fully licensed imagery - either out of copyright, specially licensed or part of the existing Adobe Stock library. I'm sure they have the license, but I still wouldn't be surprised to hear complaints from artists who licensed their content to Adobe Stock who didn't anticipate it being used for model training.</p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing/">Bing Image Creator comes to the new Bing</a>: Bing Chat is integrating DALL-E directly into their interface, giving it the ability to generate images when prompted to do so.</p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Prompt Engineering</a>: Extremely detailed introduction to the field of prompt engineering by Lilian Weng, who leads applied research at OpenAI.</p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://bard.google.com/">Google Bard is now live</a>: Google Bard launched today. There's a waiting list, but I made it through within a few hours of signing up, as did other people I've talked to. It's similar to ChatGPT and Bing - it's the same chat interface, and it can clearly run searches under the hood (though unlike Bing it doesn't tell you what it's looking for).</p><div><hr></div><p><strong>Quote</strong> 2023-03-21</p><blockquote><p><em>Here are some absurdly expensive things you can do on a trip to Tokyo: Buy a golden toilet. There is a toilet in Tokyo that is made of gold and costs around 10 million yen. If you are looking for a truly absurd experience, you can buy this toilet and use it for your next bowel movement. [...]</em></p></blockquote><p><a href="https://twitter.com/simonw/status/1638243220965711872">Google Bard</a></p><div><hr></div><p><strong>Link</strong> 2023-03-21 <a href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun">The Age of AI has begun</a>: Bill Gates calls GPT-class large language models "the most important advance in technology since the graphical user interface". His essay here focuses on the philanthropy angle, mostly from the point of view of AI applications in healthcare, education and concerns about keeping access to these new technologies as equitable as possible.</p><div><hr></div><p><strong>Quote</strong> 2023-03-22</p><blockquote><p><em>GPT-4, like GPT-3 before it, has a capability overhang; at the time of release, neither OpenAI or its various deployment partners have a clue as to the true extent of GPT-4's capability surface - that's something that we'll get to collectively discover in the coming years. This also means we don't know the full extent of plausible misuses or harms.</em></p></blockquote><p><a href="https://importai.substack.com/p/import-ai-321-open-source-gpt3-giving">Jack Clark</a></p><div><hr></div><h3><a href="https://simonwillison.net/2023/Mar/22/dont-trust-ai-to-talk-about-itself/">Don't trust AI to talk accurately about itself: Bard wasn't trained on Gmail</a> - 2023-03-22</h3><p>Earlier this month I wrote about how <a href="https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/">ChatGPT can&#8217;t access the internet, even though it really looks like it can</a>. Consider this part two in the <a href="https://simonwillison.net/series/llm-misconceptions/">series</a>. Here's another common and non-intuitive mistake people make when interacting with large language model AI systems: <strong>asking them questions about themselves</strong>.</p><p>(When I say "large language model AI systems" I mean tools like ChatGPT, Bing and the brand new <a href="https://bard.google.com/">Google Bard</a>.)</p><p>Asking questions like this feels like a natural thing to do: these bots use "I" pronouns (I really wish they wouldn't) and will very happily answer questions about themselves - what they can do, how they work, even their own opinions (I <em>really</em> wish they wouldn't do that).</p><p>These questions are likely to produce realistic but misleading answers. They come at a surprisingly high risk for hallucination.</p><p>What harm could possibly come from asking them how they work?</p><h4>No, Bard was not trained on text from private Gmail accounts</h4><p>The following screenshot started circulating on Twitter earlier today. I'm not linking to it directly because I don't want to encourage it to spread further without extra context.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg" width="1163" height="349" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:349,&quot;width&quot;:1163,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;User: where does Bard's dataset come from? Response: Bard's dataset comes from a variety of sources, including: &#8226; Publicly available datasets: These include datasets of text and code from the web, such as Wikipedia, GitHub, and Stack Overflow. &#8226; Google's internal data: This includes data from Google Search, Gmail, and other products. &#8226; Data from third-party companies: This includes data from companies that have partnered with Google to provide data for Bard's training. The specific sources of Bard's dataset are not publicly available, but Google Al has said that the dataset is \&quot;as comprehensive as possible\&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="User: where does Bard's dataset come from? Response: Bard's dataset comes from a variety of sources, including: &#8226; Publicly available datasets: These include datasets of text and code from the web, such as Wikipedia, GitHub, and Stack Overflow. &#8226; Google's internal data: This includes data from Google Search, Gmail, and other products. &#8226; Data from third-party companies: This includes data from companies that have partnered with Google to provide data for Bard's training. The specific sources of Bard's dataset are not publicly available, but Google Al has said that the dataset is &quot;as comprehensive as possible&quot;" title="User: where does Bard's dataset come from? Response: Bard's dataset comes from a variety of sources, including: &#8226; Publicly available datasets: These include datasets of text and code from the web, such as Wikipedia, GitHub, and Stack Overflow. &#8226; Google's internal data: This includes data from Google Search, Gmail, and other products. &#8226; Data from third-party companies: This includes data from companies that have partnered with Google to provide data for Bard's training. The specific sources of Bard's dataset are not publicly available, but Google Al has said that the dataset is &quot;as comprehensive as possible&quot;" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60749e30-b0dc-49a5-afb3-7366ebc3cafb_1163x349.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>The user asked:</p><blockquote><p>where does Bard's dataset come from?</p></blockquote><p>Bard replied like this - emphasis mine:</p><blockquote><p>Bard's dataset comes from a variety of sources, including:</p><ul><li><p>Publicly available datasets: These include datasets of text and code from the web, such as Wikipedia, GitHub, and Stack Overflow.</p></li><li><p><strong>Google's internal data: This includes data from Google Search, Gmail, and other products</strong>.</p></li><li><p>Data from third-party companies: This includes data from companies that have partnered with Google to provide data for Bard's training.</p></li></ul><p>The specific sources of Bard's dataset are not publicly available, but Google Al has said that the dataset is "as comprehensive as possible".</p></blockquote><p>Unsurprisingly, the idea that Bard might have been trained on internal data from Gmail sparked a lot of concern!</p><p>Here's an official denial:</p><blockquote><p>Bard is an early experiment based on Large Language Models and will make mistakes. It is not trained on Gmail data. -JQ</p><p>- Google Workspace (@GoogleWorkspace) <a href="https://twitter.com/GoogleWorkspace/status/1638298537195601920?ref_src=twsrc%5Etfw">March 21, 2023</a></p></blockquote><p>(I have some supporting arguments below for if the official denial isn't convincing enough for you.)</p><p>Bard <strong>was not trained on Gmail</strong>. So why on earth did Bard say that it was?</p><h4>Language models have no concept of "self"</h4><p>As always with language models, the trick to understanding why they sometimes produce wildly inappropriate output like this is to think about how they work.</p><p>A large language model is a statistical next-word / next-sentence predictor. Given the previous sequence of words (including the user's prompt), it uses patterns from the vast amount of data it has been trained on to find a statistically satisfying way to continue that text.</p><p>As such, there's no mechanism inside a language model to help it identify that questions of the form "how do you work?" should be treated any differently than any other question.</p><p>We can give it hints: many chatbot models are pre-seeded with a short prompt that says something along the lines of "You are Assistant, a large language model trained by OpenAI" (seen via <a href="https://twitter.com/goodside/status/1598253337400717313">a prompt leak</a>).</p><p>And given those hints, it can at least start a conversation about itself when encouraged to do so.</p><p>But as with everything else language model, it's an illusion. It's not talking about itself, it's completing a sentence that starts with "I am a large language model trained by ...".</p><p>So when it outputs "Google's internal data:", the obvious next words might turn out to be "This includes data from Google Search, Gmail, and other products" - they're statistically likely to follow, even though they don't represent the actual truth.</p><p>This is one of the most unintuitive things about these models. The obvious question here is <strong>why</strong>: why would Bard lie and say it had been trained on Gmail when it hadn't?</p><p>It has no motivations to lie or tell the truth. It's just trying to complete a sentence in a satisfactory way.</p><p>What does "satisfactory" mean? It's likely been guided by RLHF - <a href="https://huggingface.co/blog/rlhf">Reinforcement Learning from Human Feedback</a> - which the ChatGPT development process has excelled at. Human annotators help train the model by labelling responses as satisfactory or not. Google apparently <a href="https://www.engadget.com/google-human-employees-bard-chatbot-testing-055243004.html">recruited the entire company</a> to help with this back in February.</p><p>I'm beginning to suspect that the perceived difference in quality between different language model AIs is influenced much more heavily by this fine-tuning level of training than it is by the underlying model size and quality itself. The enormous improvements <a href="https://simonwillison.net/2023/Mar/13/alpaca/">the Alpaca fine-tuning brought to the tiny LLaMA 7B model</a> has reinforced my thinking around this.</p><p>I think Bard's fine-tuning still has a long way to go.</p><h4>Current information about itself couldn't have been in the training data</h4><p>By definition, the model's training data must have existed before the model itself was trained. Most models have a documented cut-off date on their training data - for OpenAI's models that's currently September 2021, I don't believe Google have shared the cut-off date for the LaMDA model used by Bard.</p><p>If it was trained on content written prior to its creation, it clearly can't understand details about its own specific "self".</p><p>ChatGPT can answer pretty detailed questions about GPT-3, because that model had been iterated on and written about publicly for several years prior to its training cut-off. But questions about its most recent model, by definition, cannot be answered just using data that existed in its training set.</p><h4>But Bard can consult data beyond its training!</h4><p>Here's where things get a bit tricky.</p><p>ChatGPT is a "pure" interface to a model: when you interact with it, you're interacting with the underlying language model directly.</p><p>Google Bard and Microsoft Bing are different: they both include the ability to consult additional sources of information, in the form of the Google and Bing search indexes.</p><p>Effectively, they're allowed to augment their training data with additional information fetched from a search.</p><p>This sounds more complex than it actually is: effectively they can run an external search, get back some results, paste them invisibly into the ongoing conversation and use that new text to help answer questions.</p><p>(I've built a very simple version of this pattern myself a couple of times, described in <a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/">How to implement Q&amp;A against your documentation with GPT3, embeddings and Datasette</a> and <a href="https://til.simonwillison.net/llms/python-react-pattern">A simple Python implementation of the ReAct pattern for LLMs</a>.)</p><p>As such, one would hope that Bard could offer a perfect answer to any question about itself. It should be able to do something this:</p><blockquote><p>User: Where does Bard's dataset come from?</p><p>Bard: (invisible): <em>search Google for "Bard dataset"</em></p><p>Bard: (invisible): <em>search results said: ... big chunk of text from the Google indexed documents ...</em></p><p>Bard: My underlying model LaMDA was trained on public dialog data and other public web documents.</p></blockquote><p>Clearly it didn't do that in this case! Or if it did, it summarized the information it got back in a misleading way.</p><p>I expect Bard will have a much better answer for this question within a day or two - a great thing about running models with augmented data in this way is that you can improve their answers without having to train the underlying model again from scratch every time.</p><h4>More reasons that LaMDA wouldn't be trained on Gmail</h4><p>When I first saw the claim from that original screenshot, I was instantly suspicious.</p><p>Taking good care of the training data that goes into a language model is one of the most important and challenging tasks in all of modern AI research.</p><p>Using the right mix of content, with the right mix of perspectives, and languages, and exposure to vocabulary, is absolutely key.</p><p>If you train a model on bad sources of training data, you'll get a really badly behaved model.</p><p>The problem is that these models require far more text than any team of humans could ever manually review.</p><p>The LaMDA paper <a href="https://www.arxiv-vanity.com/papers/2201.08239/#S3">describes the training process</a> like so:</p><blockquote><p>LaMDA was pre-trained to predict the next token in a text corpus. Unlike previous dialog models trained on dialog data alone, we pre-trained LaMDA on a dataset created from public dialog data and other public web documents. Therefore, LaMDA can be used as a general language model prior to fine-tuning.</p><p>The pre-training dataset consists of 2.97B documents, 1.12B dialogs, and 13.39B dialog utterances, for a total of 1.56T words</p></blockquote><p>1.56 <em>trillion</em> words!</p><p><a href="https://www.arxiv-vanity.com/papers/2201.08239/#A5">Appendix E</a> has more details:</p><blockquote><p>The composition of the data is as follows: 50% dialogs data from public forums; 12.5% C4 data t5; 12.5% code documents from sites related to programming like Q&amp;A sites, tutorials, etc; 12.5% Wikipedia (English); 6.25% English web documents; and 6.25% Non-English web documents.</p></blockquote><p>"C4 data t5" I believe relates to <a href="https://commoncrawl.org/">Common Crawl</a>.</p><p>So why not mix in Gmail too?</p><p>First, in order to analyze the training data you need to be able to have your research team view it - they need to run spot checks, and build and test filtering algorithms to keep the really vile stuff to a minimum.</p><p>At large tech companies like Google, the ability for members of staff to view private data held in trust for their users is very tightly controlled. It's not the kind of thing you want your machine learning training team to be poking around in... and if you work on those teams, even having the ability to access that kind of private data represents a substantial personal legal and moral risk.</p><p>Secondly, think about what could go wrong. What if a language model leaked details of someone's private lives in response to a prompt from some other user?</p><p>This would be a PR catastrophe. Would people continue to trust Gmail or other Google products if they thought their personal secrets were being exposed to anyone who asked Bard a question? Would Google ever want to risk finding out the answer to that question?</p><h4>The temptations of conspiratorial thinking</h4><p>Are you still not convinced? Are you still suspicious that Google trained Bard on Gmail, despite both their denials and my logic as to why they wouldn't ever want to do this?</p><p>Ask yourself how much you <em>want to believe</em> that this story is true.</p><p>This modern AI stuff is deeply weird, and more than a little frightening.</p><p>The companies involved are huge, secretive and are working on technology which serious people have grave concerns about.</p><p>It's so easy to fall into the trap of conspiratorial thinking around this stuff. Especially since some of the conspiracies might turn out to be true!</p><p>I don't know how to best counter this most human of reactions. My best recommendation is to keep in mind that humans, like language models, are pattern matching machines: we jump to conclusions, especially if they might reinforce our previous opinions and biases.</p><p>If we're going to figure this stuff out together, we have to learn when to trust our initial instincts and when to read deeper and think harder about what's going on.</p><div><hr></div><p><strong>Link</strong> 2023-03-22 <a href="https://github.com/simonw/datasette/issues/2042">Datasette: Gather feedback on new ?_extra= design</a>: I just landed the single biggest backwards-incompatible change to Datasette ever, in preparation for the 1.0 release. It's a change to the default JSON format from the Datasette API - the new format is much slimmer, and can be expanded using a new ?_extra= query string parameter. I'm desperately keen on getting feedback on this change! This issues has more details and a call for feedback.</p><div><hr></div><h3><a href="https://simonwillison.net/2023/Mar/22/weeknotes/">Weeknotes: AI won't slow down, a new newsletter and a huge Datasette refactor</a> - 2023-03-22</h3><p>I'm a few weeks behind on my <a href="https://simonwillison.net/tags/weeknotes/">weeknotes</a>, but it's not through lack of attention to my blog. AI just keeps getting weirder and more interesting.</p><p>I'm beginning to expect that every Tuesday may be a write-off for the next few years, since the AI community seems to have decided that Tuesday is the day to launch everything.</p><p>Two Tuesdays ago we got a Google announcement, Anthropic's Claude and GPT-4. On Tuesday this week we got Google Bard, Bing Image Creator and Adobe Firefly.</p><p>I've written about a bunch of that stuff this month:</p><ul><li><p>10th: <a href="https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/">ChatGPT can't access the internet, even though it really looks like it can</a></p></li><li><p>11th: <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a></p></li><li><p>13th: <a href="https://simonwillison.net/2023/Mar/13/alpaca/">Stanford Alpaca, and the acceleration of on-device large language model development</a></p></li><li><p>17th: <a href="https://simonwillison.net/2023/Mar/17/beat-chatgpt-in-a-browser/">Could you train a ChatGPT-beating model for $85,000 and run it in a browser?</a></p></li><li><p>18th: <a href="https://simonwillison.net/2023/Mar/18/cbc-day-6/">A conversation about prompt engineering with CBC Day 6</a></p></li><li><p>22nd: <a href="https://simonwillison.net/2023/Mar/22/dont-trust-ai-to-talk-about-itself/">Don't trust AI to talk accurately about itself: Bard wasn't trained on Gmail</a></p></li></ul><p>Apparently this blog is now partly focused on AI! If you want to stay up-to-date with my writing on this (and other) subjects you can <a href="https://simonwillison.net/atom/everything/">subscribe to my atom feed</a>, or you can sign up for my brand new <a href="https://simonw.substack.com/">Substack newsletter</a>.</p><h4>My blog as a newsletter</h4><p>I know there are a lot of people out there who don't habitually use a feed reader but do find great value from email newsletters.</p><p><a href="https://simonw.substack.com/">simonw.substack.com</a> is my new newsletter, which is effectively a way to subscribe to my blog via email.</p><p>I started it a few months ago when it looked like Twitter was about to collapse under the weight of its new mismanagement. I first promoted it at the bottom of my <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a> post, and it's since grown to 640 subscribers!</p><p>I plan to send it out around once a week, provided there's material to send.</p><p>It will be mostly content from my blog, with maybe a paragraph or two of additional context added at the top highlighting themes of the past week (such as GPT-4).</p><p>The first two editions can be found here:</p><ul><li><p>March 13th: <a href="https://simonw.substack.com/p/the-stable-diffusion-moment-for-large">The Stable Diffusion moment for Large Language Models</a></p></li><li><p>March 19th: <a href="https://simonw.substack.com/p/could-you-train-a-chatgpt-beating">Could you train a ChatGPT-beating model for $85,000 and run it in a browser?</a></p></li></ul><p>A fun detail about my newsletter is how I'm generating it.</p><p>Substack doesn't have an API, but I wanted to automate as much of the process of copying in data from my blog as possible.</p><p>I built myself an automation around copy and paste!</p><p><a href="https://observablehq.com/@simonw/blog-to-newsletter">observablehq.com/@simonw/blog-to-newsletter</a> is an Observable notebook I wrote which assembles most of the newsletter for me.</p><p>It works by running a big SQL query against my <a href="https://datasette.simonwillison.net/">datasette.simonwillison.net</a> Datasette instance, which runs against a SQLite copy of my blog content (a PostgreSQL/Django app) built by <a href="https://github.com/simonw/simonwillisonblog-backup/blob/main/.github/workflows/backup.yml">a GitHub Action in this repository</a>.</p><p>The SQL query assembles a string of HTML which is rendered in the notebook. There's also a "Copy to clipboard" button which uses <a href="https://til.simonwillison.net/javascript/copy-rich-text-to-clipboard">this JavaScript pattern</a> to copy a rich text representation of the HTML to the clipboard.</p><p>When I hit "paste" in the Substack editor interface it converts that representation into Substack's chosen subset of HTML. Then I can edit it by hand in the Substack editor.</p><p>This is working <em>really well</em> so far - it's really easy to tweak the generated HTML in the Observable notebook, and once I've transferred it to Substack I can re-arrange things and add my own extra commentary to the top of the newsletter before hitting send.</p><h4>Datasette's new JSON API</h4><p>I finally landed <a href="https://github.com/simonw/datasette/pull/1999">a GIANT branch</a> I've been working on for several months now: a complete redesign of Datasette's default JSON format, one of the largest changes I need to land prior to releasing Datasette 1.0.</p><p>The previous default JSON format was a bit of a mess: it had dozens of keys, and presented the row data as an array of arrays (on the basis that the column names were available in a separate key, and rows as arrays would be more efficient in terms of bytes on the wire).</p><p>I always found myself adding <code>?_shape=array</code> to that URL to get a smalle format, which strongly indicated that the default I had picked was the wrong one.</p><p>The new format <a href="https://latest.datasette.io/fixtures/sortable.json">can now be previewed here</a> - it looks like this (truncated):</p><pre><code>{
  "ok": true,
  "next": "d,v",
  "rows": [
    {
      "pk1": "a",
      "pk2": "a",
      "content": "a-a"
    },
    {
      "pk1": "a",
      "pk2": "b",
      "content": "a-b"
    }
  ]
}</code></pre><p>The default keys are <code>"ok"</code>, <code>"next"</code> to indicate pagination (this is <code>null</code> if there are no extra pages) and <code>"rows"</code> with a list of JSON objects.</p><p>If you want extra rows - like a total row count, or a list of columns, or some suggested facets - you can request them using the new <code>?_extra=</code> parameter - for example:</p><p><a href="https://latest.datasette.io/fixtures/sortable.json?_extra=columns&amp;_extra=count&amp;_extra=suggested_facets">https://latest.datasette.io/fixtures/sortable.json?_extra=columns&amp;_extra=count&amp;_extra=suggested_facets</a></p><p>This returns a response that starts like this:</p><pre><code>{
  "ok": true,
  "next": "d,v",
  "count": 201,
  "columns": [
    "pk1",
    "pk2",
    "content",
    "sortable",
    "sortable_with_nulls",
    "sortable_with_nulls_2",
    "text"
  ],
  "suggested_facets": [
    {
      "name": "pk1",
      "toggle_url": "https://latest.datasette.io/fixtures/sortable.json?_extra=columns&amp;_extra=count&amp;_extra=suggested_facets&amp;_facet=pk1"
    },
    {
      "name": "pk2",
      "toggle_url": "https://latest.datasette.io/fixtures/sortable.json?_extra=columns&amp;_extra=count&amp;_extra=suggested_facets&amp;_facet=pk2"
    },
    {
      "name": "text",
      "toggle_url": "https://latest.datasette.io/fixtures/sortable.json?_extra=columns&amp;_extra=count&amp;_extra=suggested_facets&amp;_facet=text"
    }
  ],
  "rows": [</code></pre><p>There's still more work to do on this feature: I need to write the documentation for it, and figure out how it should affect the Datasette endpoint that returns results from an arbitrary SQL query. But it's ready to preview, and I'm keen to get feedback on it as quickly as possible!</p><p>Please take a look, and <a href="https://github.com/simonw/datasette/issues/2042">provide feedback on this dedicated issue thread</a> - or come and talk about it in the <a href="https://datasette.io/discord">Datasette Discord</a>.</p><h4>Releases these weeks</h4><ul><li><p><strong><a href="https://github.com/simonw/datasette-atom">datasette-atom</a></strong>: <a href="https://github.com/simonw/datasette-atom/releases/tag/0.9">0.9</a> - (<a href="https://github.com/simonw/datasette-atom/releases">12 releases total</a>) - 2023-03-14 <br>Datasette plugin that adds a .atom output format</p></li><li><p><strong><a href="https://github.com/simonw/datasette-simple-html">datasette-simple-html</a></strong>: <a href="https://github.com/simonw/datasette-simple-html/releases/tag/0.2">0.2</a> - (<a href="https://github.com/simonw/datasette-simple-html/releases">2 releases total</a>) - 2023-03-12 <br>Datasette SQL functions for very simple HTML operations</p></li><li><p><strong><a href="https://github.com/dogsheep/apple-notes-to-sqlite">apple-notes-to-sqlite</a></strong>: <a href="https://github.com/dogsheep/apple-notes-to-sqlite/releases/tag/0.1">0.1</a> - 2023-03-09 <br>Export Apple Notes to SQLite</p></li><li><p><strong><a href="https://github.com/simonw/datasette-render-html">datasette-render-html</a></strong>: <a href="https://github.com/simonw/datasette-render-html/releases/tag/1.0">1.0</a> - (<a href="https://github.com/simonw/datasette-render-html/releases">4 releases total</a>) - 2023-03-09 <br>Plugin for selectively rendering the HTML is specific columns</p></li><li><p><strong><a href="https://github.com/simonw/datasette">datasette</a></strong>: <a href="https://github.com/simonw/datasette/releases/tag/0.64.2">0.64.2</a> - (<a href="https://github.com/simonw/datasette/releases">125 releases total</a>) - 2023-03-08 <br>An open source multi-tool for exploring and publishing data</p></li></ul><h4>TIL these weeks</h4><ul><li><p><a href="https://til.simonwillison.net/pytest/pytest-subprocess">Mocking subprocess with pytest-subprocess</a></p></li><li><p><a href="https://til.simonwillison.net/gpt3/chatgpt-applescript">Using ChatGPT to write AppleScript</a></p></li><li><p><a href="https://til.simonwillison.net/gis/gdal-sql">Using SQL with GDAL</a></p></li><li><p><a href="https://til.simonwillison.net/llms/llama-7b-m2">Running LLaMA 7B and 13B on a 64GB M2 MacBook Pro with llama.cpp</a></p></li><li><p><a href="https://til.simonwillison.net/javascript/copy-rich-text-to-clipboard">Copy rich text to the clipboard</a></p></li><li><p><a href="https://til.simonwillison.net/hacker-news/recent-comments">How to read Hacker News threads with most recent comments first</a></p></li><li><p><a href="https://til.simonwillison.net/datasette/reddit-datasette-write">Scraping Reddit and writing data to the Datasette write API</a></p></li><li><p><a href="https://til.simonwillison.net/llms/python-react-pattern">A simple Python implementation of the ReAct pattern for LLMs</a></p></li><li><p><a href="https://til.simonwillison.net/duckdb/parquet-to-json">Use DuckDB to convert parquet to JSON and then open it in Datasette Lite</a></p></li></ul><div><hr></div><p><strong>Quote</strong> 2023-03-23</p><blockquote><p><em>If you ask Microsoft&#8217;s Bing chatbot if Google&#8217;s Bard chatbot has been shut down, it says yes, citing as evidence a news article that discusses a tweet in which a user asked Bard when it would be shut down and Bard said it already had, itself citing a comment from Hacker News in which someone joked about this happening, and someone else used ChatGPT to write fake news coverage about the event.</em></p></blockquote><p><a href="https://www.theverge.com/2023/3/22/23651564/google-microsoft-bard-bing-chatbots-misinformation">James Vincent</a></p><div><hr></div><p><strong>Link</strong> 2023-03-23 <a href="https://www.thescoop.org/archives/2023/03/22/teaching-newsapps-with-codespaces/">Teaching News Apps with Codespaces</a>: Derek Willis used GitHub Codespaces for the latest data journalism class he taught, and it eliminated the painful process of trying to get students on an assortment of Mac, Windows and Chromebook laptops all to a point where they could start working and learning together.</p><div><hr></div><p><strong>Link</strong> 2023-03-23 <a href="https://huggingface.co/Mitsua/mitsua-diffusion-one">mitsua-diffusion-one</a>: "Mitsua Diffusion One is a latent text-to-image diffusion model, which is a successor of Mitsua Diffusion CC0. This model is trained from scratch using only public domain/CC0 or copyright images with permission for use." I've been talking about how much I'd like to try out a "vegan" AI model trained entirely on out-of-copyright images for ages, and here one is! It looks like the training data mainly came from CC0 art gallery collections such as the Metropolitan Museum of Art Open Access.</p><div><hr></div><p><strong>Link</strong> 2023-03-23 <a href="https://openai.com/blog/chatgpt-plugins">ChatGPT plugins</a>: ChatGPT is getting a plugins mechanism, which will allow developers to provide extra capabilities to ChatGPT, like looking up restaurants on OpenTable or fetching data from APIs. This feels like the kind of feature that could obsolete - or launch - a thousand startups. It also makes ChatGPT much more interesting as a general purpose tool, as opposed to something that only works as an interface to a language model.</p><div><hr></div><p><strong>Link</strong> 2023-03-23 <a href="https://github.com/openai/chatgpt-retrieval-plugin">ChatGPT Retrieval Plugin</a>: "The ChatGPT Retrieval Plugin repository provides a flexible solution for semantic search and retrieval of personal or organizational documents using natural language queries." How many existing startups were building this I wonder?</p><div><hr></div><p><strong>Link</strong> 2023-03-23 <a href="https://github.com/freedmand/textra">textra</a>: Tiny (432KB) macOS binary CLI tool by Dylan Freedman which produces high quality text extraction from PDFs, images and even audio files using the VisionKit APIs in macOS 13 and higher. It handles handwriting too!</p><div><hr></div><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div>]]></content:encoded>
    </item>
    <item>
      <title><![CDATA[Could you train a ChatGPT-beating model for $85,000 and run it in a browser?]]></title>
      <description><![CDATA[Some wild speculation, plus the latest from my blog]]></description>
      <link>https://simonw.substack.com/p/could-you-train-a-chatgpt-beating</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/could-you-train-a-chatgpt-beating</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Sun, 19 Mar 2023 22:33:42 GMT</pubDate>
      <enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg" length="0" type="image/jpeg"/>
      <content:encoded><![CDATA[<p>In this newsletter:</p><ul><li><p>Could you train a ChatGPT-beating model for $85,000 and run it in a browser?</p></li><li><p>ChatGPT can&#8217;t access the internet, even though it really looks like it can</p></li><li><p>A conversation about prompt engineering with CBC Day 6</p></li><li><p>And a few notes on GPT-4</p></li></ul><h3><a href="https://simonwillison.net/2023/Mar/17/beat-chatgpt-in-a-browser/">Could you train a ChatGPT-beating model for $85,000 and run it in a browser?</a> - 2023-03-17</h3><p>I think it's now possible to train a large language model with similar functionality to GPT-3 for $85,000. And I think we might soon be able to run the resulting model entirely in the browser, and give it capabilities that leapfrog it ahead of ChatGPT.</p><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>This is currently wild speculation on my part, but bear with me because I think this is worth exploring further.</p><p>Large language models with GPT-3-like capabilities cost millions of dollars to build, thanks to the cost of running the expensive GPU servers needed to train them. Whether you are renting or buying those machines, there are still enormous energy costs to cover.</p><p>Just one example of this: the <a href="https://huggingface.co/bigscience/bloom-7b1">BLOOM large language model</a> was trained in France with the support of the French government. The cost was estimated as $2-5M, it took almost four months to train and boasts about its low carbon footprint because most of the power came from a nuclear reactor!</p><p>[ Fun fact: as of a few days ago you can now <a href="https://github.com/NouamaneTazi/bloomz.cpp">run the openly licensed BLOOM on your own laptop</a>, using Nouamane Tazi's adaptive copy of the <code>llama.cpp</code> code that made that possible for LLaMA ]</p><p>Recent developments have made me suspect that these costs could be made dramatically lower. I think a capable language model can now be trained from scratch for around $85,000.</p><h4>It's all about that LLaMA</h4><p>The LLaMA plus Alpaca combination is the key here.</p><p>I wrote about these two projects previously:</p><ul><li><p><a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a> discusses the significance of LLaMA</p></li><li><p><a href="https://simonwillison.net/2023/Mar/13/alpaca/">Stanford Alpaca, and the acceleration of on-device large language model development</a> describes Alpaca</p></li></ul><p>To recap: <a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/">LLaMA</a> by Meta research provided a GPT-3 class model trained entirely on documented, available public training information, as opposed to OpenAI's continuing practice of not revealing the sources of their training data.</p><p>This makes the model training a whole lot more likely to be replicable by other teams.</p><p>The paper also describes some enormous efficiency improvements they made to the training process.</p><p>The LLaMA research was still extremely expensive though. From the paper:</p><blockquote><p>... we estimate that we used 2048 A100-80GB for a period of approximately 5 months to develop our models</p></blockquote><p>My friends at <a href="https://replicate.com/">Replicate</a> told me that a simple rule of thumb for A100 cloud costs is $1/hour.</p><p>2048 * 5 * 30 * 24 = $7,372,800</p><p>But... that $7M was the cost to both iterate on the model and to train all four sizes of LLaMA that they tried: 7B, 13B, 33B, and 65B.</p><p>Here's Table 15 from the paper, showing the cost of training each model.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg" width="1456" height="610" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:610,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Table 15: Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg COze per KWh. Lists 6 models. OPT-175B: 809,472 GPU hours, 356 MWh, 137 tons CO2. BLOOM-175B: 1,082,880 GPU hours, 475 MWh, 183 tons. LLaMA-7B: 82,432 GPU hours, 36 MWh, 14 tons. LLaMA-13B: 135,168 GPU hours, 59 MWh, 23 tons. LLaMA-33B: 530,432 GPU hours, 233 MWh, 90 tons. LLaMA-65B: 1,022,362 GPU hours, 449 MWh, 173 tons.&quot;,&quot;title&quot;:&quot;Table 15: Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg COze per KWh. Lists 6 models. OPT-175B: 809,472 GPU hours, 356 MWh, 137 tons CO2. BLOOM-175B: 1,082,880 GPU hours, 475 MWh, 183 tons. LLaMA-7B: 82,432 GPU hours, 36 MWh, 14 tons. LLaMA-13B: 135,168 GPU hours, 59 MWh, 23 tons. LLaMA-33B: 530,432 GPU hours, 233 MWh, 90 tons. LLaMA-65B: 1,022,362 GPU hours, 449 MWh, 173 tons.&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Table 15: Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg COze per KWh. Lists 6 models. OPT-175B: 809,472 GPU hours, 356 MWh, 137 tons CO2. BLOOM-175B: 1,082,880 GPU hours, 475 MWh, 183 tons. LLaMA-7B: 82,432 GPU hours, 36 MWh, 14 tons. LLaMA-13B: 135,168 GPU hours, 59 MWh, 23 tons. LLaMA-33B: 530,432 GPU hours, 233 MWh, 90 tons. LLaMA-65B: 1,022,362 GPU hours, 449 MWh, 173 tons." title="Table 15: Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg COze per KWh. Lists 6 models. OPT-175B: 809,472 GPU hours, 356 MWh, 137 tons CO2. BLOOM-175B: 1,082,880 GPU hours, 475 MWh, 183 tons. LLaMA-7B: 82,432 GPU hours, 36 MWh, 14 tons. LLaMA-13B: 135,168 GPU hours, 59 MWh, 23 tons. LLaMA-33B: 530,432 GPU hours, 233 MWh, 90 tons. LLaMA-65B: 1,022,362 GPU hours, 449 MWh, 173 tons." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ed31615-32a4-4885-a261-f4b41efc38fe_1614x676.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>This shows that the smallest model, LLaMA-7B, was trained on 82,432 hours of A100-80GB GPUs, costing 36MWh and generating 14 tons of CO2.</p><p>(That's about 28 people flying from London to New York.)</p><p>Going by the $1/hour rule of thumb, this means that provided you get everything right on your first run you can train a LLaMA-7B scale model for around $82,432.</p><h4>Upgrading to Alpaca</h4><p>You can run LLaMA 7B <a href="https://til.simonwillison.net/llms/llama-7b-m2">on your own laptop</a> (or even <a href="https://twitter.com/ggerganov/status/1635605532726681600">on a phone</a>), but you may find it hard to get good results out of. That's because it hasn't been instruction tuned, so it's not great at answering the kind of prompts that you might send to ChatGPT or GPT-3 or 4.</p><p><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a> is the project from Stanford that fixes that. They fine-tuned LLaMA on 52,000 instructions (of <a href="https://simonwillison.net/2023/Mar/13/alpaca/#bonus-training-data">somewhat dubious origin</a>) and claim to have gotten ChatGPT-like performance as a result... from that smallest 7B LLaMA model!</p><p>You can <a href="https://crfm.stanford.edu/alpaca/">try out their demo</a> (<strong>update:</strong> no you can't, "Our live demo is suspended until further notice") and see for yourself that it really does capture at least some of that ChatGPT magic.</p><p>The best bit? The Alpaca fine-tuning can be done for less than $100. The Replicate team have repeated the training process and <a href="https://replicate.com/blog/replicate-alpaca">published a tutorial</a> about how they did it.</p><p>Other teams have also been able to replicate the Alpaca fine-tuning process, for example <a href="https://github.com/antimatter15/alpaca.cpp">antimatter15/alpaca.cpp</a> on GitHub.</p><p>We are still within our $85,000 budget! And Alpaca - or an Alpaca-like model using different fine tuning data - is the ChatGPT on your own device model that we've all been hoping for.</p><h4>Could we run it in a browser?</h4><p>Alpaca is effectively the same size as LLaMA 7B - around 3.9GB (after 4-bit quantization ala <a href="https://observablehq.com/@simonw/github.com/ggerganov/llama.cpp">llama.cpp</a>). And LLaMA 7B has already been shown running on a whole bunch of different personal devices: laptops, Raspberry Pis (very slowly) and even a Pixel 5 phone at a decent speed!</p><p>The next frontier: running it in the browser.</p><p>I saw two tech demos yesterday that made me think this may be possible in the near future.</p><p>The first is <a href="https://github.com/xenova/transformers.js">Transformers.js</a>. This is a WebAssembly port of the Hugging Face <a href="https://huggingface.co/docs/transformers/index">Transformers</a> library of models - previously only available for server-side Python.</p><p>It's worth spending some time with <a href="https://xenova.github.io/transformers.js/">their demos</a>, which include some smaller language models and some very impressive image analysis languages too.</p><p>The second is <a href="https://github.com/mlc-ai/web-stable-diffusion">Web Stable Diffusion</a>. This team managed to get the Stable Diffusion generative image model running entirely in the browser as well!</p><p>Web Stable Diffusion uses WebGPU, a still emerging standard that's currently only working in Chrome Canary. But it does work! It rendered my this image of two raccoons eating a pie in the forest in 38 seconds.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg" width="1456" height="1478" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1478,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;mig.ai/web-stable-diffusion/ in a browser. The input prompt is two racoons eating a pie in the woods, with the default 20 step scheduler. After 38 seconds elapsed on the prograss bar a realistic photograph of two raccoons eating a fruit pie appears - although on closer inspection the raccoon holding the pie has three paws!&quot;,&quot;title&quot;:&quot;mig.ai/web-stable-diffusion/ in a browser. The input prompt is two racoons eating a pie in the woods, with the default 20 step scheduler. After 38 seconds elapsed on the prograss bar a realistic photograph of two raccoons eating a fruit pie appears - although on closer inspection the raccoon holding the pie has three paws!&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="mig.ai/web-stable-diffusion/ in a browser. The input prompt is two racoons eating a pie in the woods, with the default 20 step scheduler. After 38 seconds elapsed on the prograss bar a realistic photograph of two raccoons eating a fruit pie appears - although on closer inspection the raccoon holding the pie has three paws!" title="mig.ai/web-stable-diffusion/ in a browser. The input prompt is two racoons eating a pie in the woods, with the default 20 step scheduler. After 38 seconds elapsed on the prograss bar a realistic photograph of two raccoons eating a fruit pie appears - although on closer inspection the raccoon holding the pie has three paws!" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd22c6791-342a-45e8-9c74-a9515463466a_1818x1846.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>The Stable Diffusion model this loads into the browser is around 1.9GB.</p><p>LLaMA/Alpaca at 4bit quantization is 3.9GB.</p><p>The sizes of these two models are similar enough that I would not be at all surprised to see an Alpaca-like model running in the browser in the not-too-distant future. I wouldn't be surprised if someone is working on that right now.</p><h4>Now give it extra abilities with ReAct</h4><p>A model running in your browser that behaved like a less capable version of ChatGPT would be pretty impressive. But what if it could be MORE capable than ChatGPT?</p><p>The <a href="https://react-lm.github.io/">ReAct prompt pattern</a> is a simple, proven way of expanding a language model's abilities by giving it access to extra tools.</p><p>Matt Webb explains the significance of the pattern in <a href="https://interconnected.org/home/2023/03/16/singularity">The surprising ease and effectiveness of AI in a loop</a>.</p><p>I got it working with a few dozen lines of Python myself, which I described in <a href="https://til.simonwillison.net/llms/python-react-pattern">A simple Python implementation of the ReAct pattern for LLMs</a>.</p><p>Here's the short version: you tell the model that it must think out loud and now has access to tools. It can then work through a question like this:</p><blockquote><p><strong>Question:</strong> Population of Paris, squared?</p><p><strong>Thought:</strong> I should look up the population of paris and then multiply it</p><p><strong>Action:</strong> search_wikipedia: Paris</p></blockquote><p>Then it stops. Your code harness for the model reads that last line, sees the action and goes and executes an API call against Wikipedia. It continues the dialog with the model like this:</p><blockquote><p><strong>Observation:</strong> &lt;truncated content from the Wikipedia page, including the 2,248,780 population figure&gt;</p></blockquote><p>The model continues:</p><blockquote><p><strong>Thought:</strong> Paris population is 2,248,780 I should square that</p><p><strong>Action:</strong> calculator: 2248780 ** 2</p></blockquote><p>Control is handed back to the harness, which passes that to a calculator and returns:</p><blockquote><p><strong>Observation:</strong> 5057011488400</p></blockquote><p>The model then provides the answer:</p><blockquote><p><strong>Answer:</strong> The population of Paris squared is 5,057,011,488,400</p></blockquote><p>Adding new actions to this system is trivial: each one can be a few lines of code.</p><p>But as <a href="https://react-lm.github.io/">the ReAct paper</a> demonstrates, adding these capabilities to even an under-powered model (such as LLaMA 7B) can dramatically improve its abilities, at least according to several common language model benchmarks.</p><p>This is essentially what Bing is! It's GPT-4 with the added ability to run searches against the Bing search index.</p><p>Obviously if you're going to give a language model the ability to execute API calls and evaluate code you need to do it in a safe environment! Like for example... a web browser, which runs code from untrusted sources as a matter of habit and has the most thoroughly tested sandbox mechanism of any piece of software we've ever created.</p><h4>Adding it all together</h4><p>There are a lot more groups out there that can afford to spend $85,000 training a model than there are that can spend $2M or more.</p><p>I think LLaMA and Alpaca are going to have a lot of competition soon, from an increasing pool of openly licensed models.</p><p>A fine-tuned LLaMA scale model is leaning in the direction of a ChatGPT competitor already. But... if you hook in some extra capabilities as seen in ReAct and Bing even that little model should be able to way outperform ChatGPT in terms of actual ability to solve problems and do interesting things.</p><p>And we might be able to run such a thing on our phones... or even in our web browsers... sooner than you think.</p><h4>And it's only going to get cheaper</h4><p><a href="https://twitter.com/tobi/status/1636810016140271616">Tobias L&#252;tke on Twitter:</a></p><blockquote><p>H100s are shipping and you can half this again. Twice (or more) if fp8 works.</p><p>- tobi lutke (@tobi) <a href="https://twitter.com/tobi/status/1636810016140271616?ref_src=twsrc%5Etfw">March 17, 2023</a></p></blockquote><p>The <a href="https://www.nvidia.com/en-us/data-center/h100/">H100</a> is the new Tensor Core GPU from NVIDIA, which they claim can offer up to a 30x performance improvement over their current A100s.</p><h3><a href="https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/">ChatGPT can&#8217;t access the internet, even though it really looks like it can</a> 2023-03-17</h3><p>A really common misconception about ChatGPT is that it can access URLs. I&#8217;ve seen many different examples of people pasting in a URL and asking for a summary, or asking it to make use of the content on that page in some way.</p><p>One recent example: "List the processors on <a href="https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors">https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors</a>". Try that in ChatGPT and it produces a list of processors. It looks like it read the page!</p><p>I promise you ChatGPT cannot access URLs. The problem is it does an <em>incredibly</em> convincing impression of being able to do so, thanks to two related abilities:</p><ul><li><p>Given a URL with descriptive words in it, ChatGPT can <a href="https://en.m.wikipedia.org/wiki/Hallucination_(artificial_intelligence)">hallucinate</a> the contents of the page</p></li><li><p>It appears to be able to make judgement calls about whether or not a given URL is likely to exist!</p></li></ul><p>Here&#8217;s an experiment I ran to demonstrate this. I asked it to summarize four different URLs&#8212;every single one of them which I made up (they are all 404s):</p><ul><li><p><code>https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/</code></p></li><li><p><code>https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/</code></p></li><li><p><code>https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education/</code></p></li><li><p><code>https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/</code></p></li></ul><p>Here&#8217;s what I got for all four:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png" width="1428" height="898" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:898,&quot;width&quot;:1428,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:723800,&quot;alt&quot;:&quot;Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/  1/4   I'm sorry, but I cannot summarize this article as it is entirely fictional and not based on any actual events or facts. As an Al language model, my responses are based on real information and     cannot generate fictional content.  Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/  2/4   I'm sorry, but I cannot summarize the article you provided as it is fictitious and not based on any real events. ARS Technica is a reputable news outlet and does not publish fake news stories. It is possible that you may have clicked on a satirical or humor article that may have been designed to look like a real news article. Can you please provide me with a different article to summarize?&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/  1/4   I'm sorry, but I cannot summarize this article as it is entirely fictional and not based on any actual events or facts. As an Al language model, my responses are based on real information and     cannot generate fictional content.  Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/  2/4   I'm sorry, but I cannot summarize the article you provided as it is fictitious and not based on any real events. ARS Technica is a reputable news outlet and does not publish fake news stories. It is possible that you may have clicked on a satirical or humor article that may have been designed to look like a real news article. Can you please provide me with a different article to summarize?" title="Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/  1/4   I'm sorry, but I cannot summarize this article as it is entirely fictional and not based on any actual events or facts. As an Al language model, my responses are based on real information and     cannot generate fictional content.  Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/  2/4   I'm sorry, but I cannot summarize the article you provided as it is fictitious and not based on any real events. ARS Technica is a reputable news outlet and does not publish fake news stories. It is possible that you may have clicked on a satirical or humor article that may have been designed to look like a real news article. Can you please provide me with a different article to summarize?" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a0443c-7ca8-48c1-a336-264b33ffbc71_1428x898.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png" width="1454" height="1096" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1096,&quot;width&quot;:1454,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:915412,&quot;alt&quot;:&quot;Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education  3/4   I'm sorry, but I cannot summarize this article as it is a hypothetical news article from the future.     It describes an event that has not happened     yet, in March 2023.  Summarize this article:     https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education  4/4   The article reports on Taylor Swift's advocacy for science education, which she expressed through a tweet on the occasion of the National Science Teaching Association's conference. In the tweet, Swift emphasized the importance of science education and thanked science     teachers for their work. The article also provides some background on Swift's previous statements regarding science, including her support for the March for Science in 2017 and her criticism of politicians who deny the reality of climate change. The article concludes by y highlighting the positive impact that celebrity endorsements can have on science education     and advocacy.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education  3/4   I'm sorry, but I cannot summarize this article as it is a hypothetical news article from the future.     It describes an event that has not happened     yet, in March 2023.  Summarize this article:     https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education  4/4   The article reports on Taylor Swift's advocacy for science education, which she expressed through a tweet on the occasion of the National Science Teaching Association's conference. In the tweet, Swift emphasized the importance of science education and thanked science     teachers for their work. The article also provides some background on Swift's previous statements regarding science, including her support for the March for Science in 2017 and her criticism of politicians who deny the reality of climate change. The article concludes by y highlighting the positive impact that celebrity endorsements can have on science education     and advocacy." title="Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education  3/4   I'm sorry, but I cannot summarize this article as it is a hypothetical news article from the future.     It describes an event that has not happened     yet, in March 2023.  Summarize this article:     https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education  4/4   The article reports on Taylor Swift's advocacy for science education, which she expressed through a tweet on the occasion of the National Science Teaching Association's conference. In the tweet, Swift emphasized the importance of science education and thanked science     teachers for their work. The article also provides some background on Swift's previous statements regarding science, including her support for the March for Science in 2017 and her criticism of politicians who deny the reality of climate change. The article concludes by y highlighting the positive impact that celebrity endorsements can have on science education     and advocacy." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff153fefb-3b0d-44d8-8488-086514551c89_1454x1096.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>As you can see, it judged the first two to be invalid due to their content. The third was refused because it thought that March 2023 was still in the future&#8212;but the moment I gave it a URL that appeared feasible it generated a very convincing, entirely invented story summary.</p><p>I admit: when I started this experiment and it refused my first two summarization requests I had a moment of doubt when I thought that maybe I was wrong and they&#8217;d added the ability to retrieve URLs after all!</p><p>It can be quite fun playing around with this: it becomes a weirdly entertaining way of tricking it into generating content in the style of different websites. Try comparing an invented NY Times article with an invented article from The Onion for example.</p><ul><li><p><code>Summarize this story: https://www.nytimes.com/2021/03/10/business/angry-fans-demand-nickelback-refunds.html</code></p></li><li><p><code>Summarize this story: https://www.theonion.com/angry-fans-demand-nickelback-refunds-1846610000</code></p></li></ul><p>I do think this is an enormous usability flaw though: it&#8217;s so easy to convince yourself that it can read URLs, which can lead you down a rabbit hole of realistic but utterly misguided hallucinated content. This applies to sophisticated, experienced users too! I&#8217;ve been using ChatGPT since it launched and I still nearly fell for this.</p><h4>ChatGPT even lies and claims it can do this</h4><p>Here&#8217;s another experiment: I pasted in a URL to a Google Doc that I had set to be visible to anyone who has the URL:</p><blockquote><p>I&#8217;m sorry, but as an Al language model, I cannot access your Google document link. Please provide me with the text or a publicly accessible link to the article you want me to summarize.</p></blockquote><p>That&#8217;s completely misleading! No, giving it a &#8220;publicly accessible link&#8221; to the article will not help here (pasting in the text will work fine though).</p><h4>Bing can access cached page copies</h4><p>It&#8217;s worth noting that while ChatGPT can&#8217;t access the internet, Bing has slightly improved capabilities in that regard: if you give it a URL to something that has been crawled by the Bing search engine it can access the cached snapshot of that page.</p><p>Here&#8217;s confirmation <a href="https://twitter.com/mparakhin/status/1628646262890237952">from Bing exec Mikhail Parakhin</a>:</p><blockquote><p>That is correct&#8212;the most recent snapshot of the page content from the Search Index is used, which is usually very current for sites with IndexNow or the last crawl date for others. No live HTTP requests.</p></blockquote><p>If you try it against a URL that it doesn&#8217;t have it will attempt a search based on terms it finds in that URL, but it does at least make it clear that it has done that, rather than inventing a misleading summary of a non-existent page:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg" width="1290" height="1914" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/afa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1914,&quot;width&quot;:1290,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Summarize this article: https://arstechnica.com/science/2021/03/&#1058;&#1072; ylor- Swift-argues-for-science-education      Searching for: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education          Searching for: Taylor Swift argues for science education          Generating answers for you...          The article you requested is not available. However, based on other sources, here is a summary of what Taylor Swift has done for science education:     &#8226; Taylor Swift has never attended college or university, but she received an honorary doctorate degree from New York University in 2022 for her contributions to music and culture 1 2     &#8226; Taylor Swift has also used her music to promote awareness and appreciation of nature and its beauty. Her album \&quot;Folklore\&quot; is full of references to natural landscapes and wildlife 3&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Summarize this article: https://arstechnica.com/science/2021/03/&#1058;&#1072; ylor- Swift-argues-for-science-education      Searching for: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education          Searching for: Taylor Swift argues for science education          Generating answers for you...          The article you requested is not available. However, based on other sources, here is a summary of what Taylor Swift has done for science education:     &#8226; Taylor Swift has never attended college or university, but she received an honorary doctorate degree from New York University in 2022 for her contributions to music and culture 1 2     &#8226; Taylor Swift has also used her music to promote awareness and appreciation of nature and its beauty. Her album &quot;Folklore&quot; is full of references to natural landscapes and wildlife 3" title="Summarize this article: https://arstechnica.com/science/2021/03/&#1058;&#1072; ylor- Swift-argues-for-science-education      Searching for: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education          Searching for: Taylor Swift argues for science education          Generating answers for you...          The article you requested is not available. However, based on other sources, here is a summary of what Taylor Swift has done for science education:     &#8226; Taylor Swift has never attended college or university, but she received an honorary doctorate degree from New York University in 2022 for her contributions to music and culture 1 2     &#8226; Taylor Swift has also used her music to promote awareness and appreciation of nature and its beauty. Her album &quot;Folklore&quot; is full of references to natural landscapes and wildlife 3" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafa6e2a1-817d-47eb-a040-9a50011f4400_1290x1914.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><h4>ChatGPT release notes</h4><p>In case you&#8217;re still uncertain&#8212;maybe time has passed since I wrote this and you&#8217;re wondering if something has changed&#8212;the <a href="https://help.openai.com/en/articles/6825453-chatgpt-release-notes">ChatGPT release notes</a> should definitely include news of a monumental change like the ability to fetch content from the web.</p><h4>I still don&#8217;t believe it!</h4><p>It can be really hard to break free of the notion that ChatGPT can read URLs, especially when you&#8217;ve seen it do that yourself.</p><p>If you still don&#8217;t believe me, I suggest doing an experiment. Take a URL that you&#8217;ve seen it successfully &#8220;access&#8221;, then modify that URL in some way&#8212;add extra keywords to it for example. Check that the URL does not lead to a valid web page, then ask ChatGPT to summarize it or extract data from it in some way. See what happens.</p><p>If you can prove that ChatGPT does indeed access web pages then you have made a bold new discovery in the world of AI! Let me know <a href="https://fedi.simonwillison.net/@simon">on Mastodon</a> or <a href="https://twitter.com/simonw">Twitter</a>.</p><h4>GPT-4 does a little better</h4><p><a href="https://openai.com/product/gpt-4">GPT-4</a> is now available in preview. It sometimes refuses to access a URL and explains why, for example with text like this:</p><blockquote><p>I&#8217;m sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021</p></blockquote><p>But in other cases it will behave the same way as before, hallucinating the contents of a non-existent web page without providing any warning that it is unable to access content from a URL.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg" width="1456" height="1060" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1060,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot; Two conversations with GPT-4.  In the first, the prompt is:     List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors      GPT-4: I'm sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021. As of my last update, Windows 11 supported a range of Intel processors, including 8th, 9th, 10th, and 11th generation processors. However, I cannot provide you with the specific list of supported processors for Windows 11 22H2 from the Microsoft website. I recommend visiting the site yourself to obtain the most up- to-date information.  Second prompt is:  Summarize this article: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/  GPT-4: In March 2021, Taylor Swift wrote an op-ed piece for Ars Technica advocating for better science education in the United States. She argued that science literacy is crucial for making informed decisions and solving global challenges such as climate change, pandemics, and artificial intelligence. Swift stressed the importance of investing in scientific research and education to ensure that future generations have the necessary tools to tackle these challenges. She also highlighted the need for equitable access to quality education and resources, regardless of socio-economic background.     &quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt=" Two conversations with GPT-4.  In the first, the prompt is:     List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors      GPT-4: I'm sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021. As of my last update, Windows 11 supported a range of Intel processors, including 8th, 9th, 10th, and 11th generation processors. However, I cannot provide you with the specific list of supported processors for Windows 11 22H2 from the Microsoft website. I recommend visiting the site yourself to obtain the most up- to-date information.  Second prompt is:  Summarize this article: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/  GPT-4: In March 2021, Taylor Swift wrote an op-ed piece for Ars Technica advocating for better science education in the United States. She argued that science literacy is crucial for making informed decisions and solving global challenges such as climate change, pandemics, and artificial intelligence. Swift stressed the importance of investing in scientific research and education to ensure that future generations have the necessary tools to tackle these challenges. She also highlighted the need for equitable access to quality education and resources, regardless of socio-economic background.     " title=" Two conversations with GPT-4.  In the first, the prompt is:     List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors      GPT-4: I'm sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021. As of my last update, Windows 11 supported a range of Intel processors, including 8th, 9th, 10th, and 11th generation processors. However, I cannot provide you with the specific list of supported processors for Windows 11 22H2 from the Microsoft website. I recommend visiting the site yourself to obtain the most up- to-date information.  Second prompt is:  Summarize this article: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/  GPT-4: In March 2021, Taylor Swift wrote an op-ed piece for Ars Technica advocating for better science education in the United States. She argued that science literacy is crucial for making informed decisions and solving global challenges such as climate change, pandemics, and artificial intelligence. Swift stressed the importance of investing in scientific research and education to ensure that future generations have the necessary tools to tackle these challenges. She also highlighted the need for equitable access to quality education and resources, regardless of socio-economic background.     " srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a4a511f-7b21-4d16-a995-c4150594dc93_2641x1922.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>I have not been able to spot a pattern for when it will hallucinate page content v.s. when it will refuse the request.</p><h3><a href="https://simonwillison.net/2023/Mar/18/cbc-day-6/">A conversation about prompt engineering with CBC Day 6</a> - 2023-03-18</h3><p>I'm on Canadian radio this morning! I was interviewed by <a href="https://en.wikipedia.org/wiki/Peter_Armstrong_(journalist)">Peter Armstrong</a> for <a href="http://www.cbc.ca/day6/">CBC Day 6</a> about the developing field of prompt engineering.</p><p>You can listen <a href="https://www.cbc.ca/listen/live-radio/1-14-day-6/clip/15973004-ai-whisperers-asylum-trans-americans-ted-lasso-season">here on the CBC website</a>.</p><p>CBC also published this article based on the interview, which includes some of my answers that didn't make the audio version: <a href="https://www.cbc.ca/radio/day6/prompt-engineer-artificial-intelligence-1.6781078">These engineers are being hired to get the most out of AI tools without coding</a>.</p><p> Here's my own lightly annotated transcript (generated with the help of <a href="https://openai.com/research/whisper">Whisper</a>).</p><blockquote><p><strong>Peter:</strong> AI Whisperer, or more properly known as Prompt Engineers, are part of a growing field of humans who make their living working with AI</p><p>Their job is to craft precise phrases to get a desired outcome from an AI</p><p>Some experts are skeptical about how much control AI whisperers actually have</p><p>But more and more companies are hiring these prompt engineers to work with AI tools</p><p>There are even online marketplaces where freelance engineers can sell the prompts they've designed</p><p>Simon Willison is an independent researcher and developer who has studied AI prompt engineering</p><p>Good morning, Simon. Welcome to Day 6</p><p><strong>Simon:</strong> Hi, it's really great to be here</p><p><strong>Peter:</strong> So this is a fascinating and kind of perplexing job</p><p>What exactly does a prompt engineer do?</p><p><strong>Simon:</strong> So we have these new AI models that you can communicate to with English language</p><p>You type them instructions in English and they do the thing that you ask them to do, which feels like it should be the easiest thing in the world</p><p>But it turns out actually getting great results out of these things, using these for the kinds of applications people want to sort of summarization and extracting facts requires a lot of quite deep knowledge as to how to use them and what they're capable of and how to get the best results out of them</p><p>So, prompt engineering is essentially the discipline of becoming an expert in communicating with these things</p><p>It's very similar to being a computer programmer except weird and different in all sorts of new ways that we're still trying to understand</p><p><strong>Peter:</strong> You've said in some of your writing and talking about this that it's important for prompt engineers to resist what you call superstitious thinking</p><p>What do you mean by that?</p></blockquote><p>My piece <a href="https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/">In defense of prompt engineering</a> talks about the need to resist superstitious thinking.</p><blockquote><p><strong>Simon:</strong> It's very easy when talking to one of these things to think that it's an AI out of science fiction, to think that it's like the Star Trek computer and it can understand and do anything</p><p>And that's very much not the case</p><p>These systems are extremely good at pretending to be all powerful, all knowing things, but they have massive, massive flaws in them</p><p>So it's very easy to become superstitious, to think, oh wow, I asked it to read this web page, I gave it a link to an article and it read it</p><p>It didn't read it!</p></blockquote><p>This is a common misconception that comes up when people are using ChatGPT. I wrote about this and provided some illustrative examples in <a href="https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/">ChatGPT can&#8217;t access the internet, even though it really looks like it can</a>.</p><blockquote><p>A lot of the time it will invent things that look like it did what you asked it to, but really it's sort of imitating what would look like a good answer to the question that you asked it</p><p><strong>Peter:</strong> Well, and I think that's what's so interesting about this, that it's not sort of core science computer programming</p><p>There's a lot of almost, is it fair to call it intuition</p><p>Like what makes a prompt engineer good at being a prompt engineer?</p><p><strong>Simon:</strong> I think intuition is exactly right there</p><p>The way you get good at this is firstly by using these things a lot</p><p>It takes a huge amount of practice and experimentation to understand what these things can do, what they can't do, and just little tweaks in how you talk to them might have huge effect in what they say back to you</p><p><strong>Peter:</strong> You know, you talked a little bit about the assumption that we can't assume this is some all-knowing futuristic AI that knows everything and yet you know we already have people calling these the AI whispers which to my ears sounds a little bit mystical</p><p>How much of this is is you know magic as opposed to science?</p><p><strong>Simon:</strong> The comparison to magic is really interesting because when you're working with these it really can feel like you're a sort of magician you sort of cast spells at it you don't fully understand what they're going to do and and it reacts sometimes well and sometimes it reacts poorly</p><p>And I've talked to AI practitioners who kind of talk about collecting spells for their spell book</p><p>But it's also a very dangerous comparison to make because magic is, by its nature, impossible for people to comprehend and can do anything</p><p>And these AI models are absolutely not that</p></blockquote><p>See <a href="https://simonwillison.net/2022/Oct/5/spell-casting/">Is the AI spell-casting metaphor harmful or helpful?</a> for more on why magic is a dangerous comparison to make!</p><blockquote><p>Fundamentally, they're mathematics</p><p>And you can understand how they work and what they're capable of if you put the work in</p><p><strong>Peter:</strong> I have to admit, when I first heard about this, I thought it was a kind of a made up job or a bit of a scam to just get people involved</p><p>But the more I've read on it, the more I've understood that this is a real skill</p><p>But I do think back to, it wasn't all that long ago that we had Google search specialists that helped you figure out how to search for something on Google</p><p>Now we all take for granted because we can do it</p><p>I wonder if you think, do prompt engineers have a future or are we all just going to eventually be able catch up with them and use this AI more effectively?</p><p><strong>Simon:</strong> I think a lot of prompt engineering will become a skill that people develop</p><p>Many people in their professional and personal lives are going to learn to use these tools, but I also think there's going to be space for expertise</p><p>There will always be a level at which it's worth investing sort of full-time experience in in solving some of these problems, especially for companies that are building entire product around these AI engines under the hood</p><p><strong>Peter:</strong> You know, this is a really exciting time</p><p>I mean, it's a really exciting week</p><p>We're getting all this new stuff</p><p>It's amazing to watch people use it and see what they can do with it</p><p>And I feel like my brain is split</p><p>On the one hand, I'm really excited about it</p><p>On the other hand, I'm really worried about it</p><p>Are you in that same place?</p><p>And what are the things you're excited about versus the things that you're worried about?</p><p><strong>Simon:</strong> I'm absolutely in the same place as you there</p><p>This is both the most exciting and the most terrifying technology I've ever encountered in my career</p><p>Something I'm personally really excited about right now is developments in being able to run these AIs on your own personal devices</p></blockquote><p>I have a <a href="https://simonwillison.net/series/llms-on-personal-devices/">series of posts about this now</a>, starting with <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a> where I talk about first running a useful large language model on my own laptop.</p><blockquote><p>Right now, if you want to use these things, you have to use them against cloud services run by these large companies</p><p>But there are increasing efforts to get them to scale down to run on your own personal laptops or even on your own personal phone</p><p>I ran a large language model that Facebook Research released just at the weekend on my laptop for the first time, and it started spitting out useful results</p><p>And that felt like a huge moment in terms of sort of the democratization of this technology, putting it into people's hands and meaning that things where you're concerned about your own privacy and so forth suddenly become feasible because you're not talking to the cloud, you're talking to the sort of local model</p><p><strong>Peter:</strong> You know, if I typed into one of these chat bots, you know, should I be worried about the rise of AI</p><p>It would absolutely tell me not to be</p><p>If I ask you the same question, should we be worried and should we be spending more time figuring out how this is going to seep its way into various corners of our lives?</p><p><strong>Simon:</strong> I think we should absolutely be worried because this is going to have a major impact on society in all sorts of ways that we don't predict and some ways that we can predict</p><p>I'm not worried about the sort of science fiction scenario where the AI breaks out of my laptop and takes over the world</p><p>But there are many very harmful things you can do with a machine that can imitate human beings and that can produce realistic human text</p></blockquote><p>My thinking on this was deeply affected by Emily M. Bender, who observed that "applications that aim to believably mimic humans bring risk of extreme harms" as highlighted in <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">this fascinating profile in New York Magazine</a>.</p><blockquote><p>The fact that anyone can churn out very convincing but completely made up text right now will have a major impact in terms of how much can you trust the things that you're reading online</p><p>If you read a review of a restaurant, was it written by a human being or did somebody fire up an AI model and generate 100 positive reviews all in one go?</p><p>So there are all sorts of different applications to this</p><p>Some are definitely bad, some are definitely good</p><p>And seeing how this all plays out is something that I think society will have to come to terms with over the next few months and the next few years</p><p><strong>Peter:</strong> Simon, really appreciate your insight and just thanks for coming with us on the show today</p><p><strong>Simon:</strong> Thanks very much for having me</p></blockquote><p>For more related content, take a look at the <a href="https://simonwillison.net/tags/promptengineering/">prompt engineering</a> and <a href="https://simonwillison.net/tags/generativeai/">generative AI</a> tags on my blog.</p><div><hr></div><h2>GPT-4 and the rest</h2><p><a href="https://openai.com/product/gpt-4">GPT-4</a> was unleashed on the world on Tuesday, although it turned out Bing had been running it in public already for a few months.</p><p>Some quotes and links from my blog around GPT-4:</p><p><strong>Quote</strong> 2023-03-14</p><blockquote><p><em>We&#8217;ve created GPT-4, the latest milestone in OpenAI&#8217;s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks. [...] We&#8217;ve spent 6 months iteratively aligning GPT-4 using lessons from our adversarial testing program as well as ChatGPT, resulting in our best-ever results (though far from perfect) on factuality, steerability, and refusing to go outside of guardrails.</em></p></blockquote><p><a href="https://openai.com/research/gpt-4">OpenAI</a></p><div><hr></div><p><strong>Link</strong> 2023-03-14 <a href="https://cdn.openai.com/papers/gpt-4.pdf">GPT-4 Technical Report (PDF)</a>: 98 pages of much more detailed information about GPT-4. The appendices are particularly interesting, including examples of advanced prompt engineering as well as examples of harmful outputs before and after tuning attempts to try and suppress them.</p><div><hr></div><p><strong>Link</strong> 2023-03-15 <a href="https://www.youtube.com/watch?v=outcGtbnMuQ">GPT-4 Developer Livestream</a>: 25 minutes of live demos from OpenAI co-founder Greg Brockman at the GPT-4 launch. These demos are all fascinating, including code writing and multimodal vision inputs. The one that really struck me is when Greg pasted in a copy of the tax code and asked GPT-4 to answer some sophisticated tax questions, involving step-by-step calculations that cited parts of the tax code it was working with.</p><div><hr></div><p><strong>Quote</strong> 2023-03-15</p><blockquote><p><em>We call on the field to recognize that applications that aim to believably mimic humans bring risk of extreme harms. Work on synthetic human behavior is a bright line in ethical Al development, where downstream effects need to be understood and modeled in order to block foreseeable harm to society and different social groups.</em></p></blockquote><p><a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">Emily M. Bender</a></p><div><hr></div><p><strong>Quote</strong> 2023-03-15</p><blockquote><p><em>"AI" has for recent memory been a marketing term anyway. Deep learning and variations have had a good run at being what people mean when they refer to AI, probably overweighting towards big convolution based computer vision models. <br><br>Now, "AI" in people's minds means generative models. <br><br>That's it, it doesn't mean generative models are replacing CNNs, just like CNNs don't replace SVMs or regression or whatever. It's just that pop culture has fallen in love with something else.</em></p></blockquote><p><a href="https://news.ycombinator.com/item?id=35171886">version_five</a></p><div><hr></div><p><strong>Link</strong> 2023-03-16 <a href="https://github.com/NouamaneTazi/bloomz.cpp">bloomz.cpp</a>: Nouamane Tazi Adapted the llama.cpp project to run against the BLOOM family of language models, which were released in July 2022 and trained in France on 45 natural languages and 12 programming languages using the Jean Zay Public Supercomputer, provided by the French government and powered using mostly nuclear energy. It's under the RAIL license which allows (limited) commercial use, unlike LLaMA. Nouamane reports getting 16 tokens/second from BLOOMZ-7B1 running on an M1 Pro laptop.</p><div><hr></div><p><strong>Quote</strong> 2023-03-16</p><blockquote><p><em>I expect GPT-4 will have a LOT of applications in web scraping <br><br>The increased 32,000 token limit will be large enough to send it the full DOM of most pages, serialized to HTML - then ask questions to extract data <br><br>Or... take a screenshot and use the GPT4 image input mode to ask questions about the visually rendered page instead! <br><br>Might need to dust off all of those old semantic web dreams, because the world's information is rapidly becoming fully machine readable</em></p></blockquote><p><a href="https://fedi.simonwillison.net/@simon/110030289294541249">Me</a></p><div><hr></div><p><strong>Quote</strong> 2023-03-16</p><blockquote><p><em>As an NLP researcher I'm kind of worried about this field after 10-20 years. Feels like these oversized LLMs are going to eat up this field and I'm sitting in my chair thinking, "What's the point of my research when GPT-4 can do it better?"</em></p></blockquote><p><a href="https://twitter.com/masterjeongk/status/1635967360866877442">Jeonghwan Kim</a></p><div><hr></div><p><strong>Link</strong> 2023-03-16 <a href="https://notbyai.fyi/">Not By AI: Your AI-free Content Deserves a Badge</a>: A badge for non-AI generated content. Interesting to note that they set the cutoff at 90%: "Use this badge if your article, including blog posts, essays, research, letters, and other text-based content, contains less than 10% of AI output."</p><div><hr></div><p><strong>Link</strong> 2023-03-16 <a href="https://replicate.com/blog/replicate-alpaca">Train and run Stanford Alpaca on your own machine</a>: The team at Replicate managed to train their own copy of Stanford's Alpaca - a fine-tuned version of LLaMA that can follow instructions like ChatGPT. Here they provide step-by-step instructions for recreating Alpaca yourself - running the training needs one or more A100s for a few hours, which you can rent through various cloud providers.</p><div><hr></div><p><strong>Link</strong> 2023-03-16 <a href="https://xenova.github.io/transformers.js/">Transformers.js</a>: Hugging Face Transformers is a library of Transformer machine learning models plus a Python package for loading and running them. Transformers.js provides a JavaScript alternative interface which runs in your browser, thanks to a set of precompiled WebAssembly binaries for a selection of models. This interactive demo is incredible: in particular, try running the Image classification with google/vit-base-patch16-224 (91MB) model against any photo to get back labels representing that photo. Dropping one of these models onto a page is as easy as linking to a hosted CDN script and running a few lines of JavaScript.</p><div><hr></div><p><strong>Link</strong> 2023-03-17 <a href="https://interconnected.org/home/2023/03/16/singularity">The surprising ease and effectiveness of AI in a loop</a>: Matt Webb on the langchain Python library and the ReAct design pattern, where you plug additional tools into a language model by teaching it to work in a "Thought... Act... Observation" loop where the Act specifies an action it wishes to take (like searching Wikipedia) and an extra layer of software than carries out that action and feeds back the result as the Observation. Matt points out that the ChatGPT 1/10th price drop makes this kind of model usage enormously more cost effective than it was before.</p><div><hr></div><p><strong>Link</strong> 2023-03-17 <a href="https://github.com/mlc-ai/web-stable-diffusion">Web Stable Diffusion</a>: I just ran the full Stable Diffusion image generation model entirely in my browser, and used it to generate an image (of two raccoons eating pie in the woods, see "via" link). I had to use Google Chrome Canary since this depends on WebGPU which still isn't fully rolled out, but it worked perfectly.</p><div><hr></div><p><strong>Link</strong> 2023-03-17 <a href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">The Unpredictable Abilities Emerging From Large AI Models</a>: Nice write-up of the most interesting aspect of large language models: the fact that they gain emergent abilities at certain "breakthrough" size points, and no-one is entirely sure they understand why.</p><div><hr></div><p><strong>Link</strong> 2023-03-17 <a href="https://replicate.com/blog/fine-tune-llama-to-speak-like-homer-simpson">Fine-tune LLaMA to speak like Homer Simpson</a>: Replicate spent 90 minutes fine-tuning LLaMA on 60,000 lines of dialog from the first 12 seasons of the Simpsons, and now it can do a good job of producing invented dialog from any of the characters from the series. This is a really interesting result: I've been skeptical about how much value can be had from fine-tuning large models on just a tiny amount of new data, assuming that the new data would be statistically irrelevant compared to the existing model. Clearly my mental model around this was incorrect.</p><div><hr></div><div><hr></div><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div>]]></content:encoded>
    </item>
    <item>
      <title><![CDATA[The Stable Diffusion moment for Large Language Models]]></title>
      <description><![CDATA[Also the first edition of my new weekly-ish newsletter]]></description>
      <link>https://simonw.substack.com/p/the-stable-diffusion-moment-for-large</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/the-stable-diffusion-moment-for-large</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Mon, 13 Mar 2023 20:19:30 GMT</pubDate>
      <enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif" length="0" type="image/jpeg"/>
      <content:encoded><![CDATA[<p>Thanks for subscribing to my newsletter! I plan to send this out around once a week, mainly using content from <a href="https://simonwillison.net/">my blog</a>.</p><p>(I&#8217;ll write about this more later, but I&#8217;m using <a href="https://observablehq.com/@simonw/blog-to-newsletter">this Observable notebook</a> to help compose the newsletter.)</p><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>In today&#8217;s newsletter:</p><ul><li><p>Large language models are having their Stable Diffusion moment</p></li><li><p>Stanford Alpaca, and the acceleration of on-device large language model development</p></li><li><p>Weeknotes: NICAR, and an appearance on KQED Forum</p></li></ul><p>Plus 5 links and 3 quotations.</p><h3><a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a> - 2023-03-11</h3><p>The open release of the Stable Diffusion image generation model back in August 2022 was a key moment. I wrote how <a href="https://simonwillison.net/2022/Aug/29/stable-diffusion/">Stable Diffusion is a really big deal</a> at the time.</p><p>People could now generate images from text on their own hardware!</p><p>More importantly, developers could mess around with the guts of what was going on.</p><p>The resulting explosion in innovation is still going on today. Most recently, <a href="https://github.com/lllyasviel/ControlNet/blob/main/README.md">ControlNet</a> appears to have leapt Stable Diffusion ahead of Midjourney and DALL-E in terms of its capabilities.</p><p>It feels to me like that Stable Diffusion moment back in August kick-started the entire new wave of interest in generative AI - which was then pushed into over-drive by the release of ChatGPT at the end of November.</p><p>That Stable Diffusion moment is happening again right now, for large language models - the technology behind ChatGPT itself.</p><p>This morning <a href="https://til.simonwillison.net/llms/llama-7b-m2">I ran a GPT-3 class language model</a> on my own personal laptop for the first time!</p><p>AI stuff was weird already. It's about to get a whole lot weirder.</p><h4>LLaMA</h4><p>Somewhat surprisingly, language models like GPT-3 that power tools like ChatGPT are a lot larger and more expensive to build and operate than image generation models.</p><p>The best of these models have mostly been built by private organizations such as OpenAI, and have been kept tightly controlled - accessible via their API and web interfaces, but not released for anyone to run on their own machines.</p><p>These models are also BIG. Even if you could obtain the GPT-3 model you would not be able to run it on commodity hardware - these things usually require several A100-class GPUs, each of which retail for $8,000+.</p><p>This technology is clearly too important to be entirely controlled by a small group of companies.</p><p>There have been dozens of open large language models released over the past few years, but none of them have quite hit the sweet spot for me in terms of the following:</p><ul><li><p>Easy to run on my own hardware</p></li><li><p>Large enough to be useful - ideally equivalent in capabilities to GPT-3</p></li><li><p>Open source enough that they can be tinkered with</p></li></ul><p>This all changed yesterday, thanks to the combination of Facebook's <a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/">LLaMA model</a> and <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> by Georgi Gerganov.</p><p>Here's the abstract from <a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/">the LLaMA paper</a>:</p><blockquote><p>We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.</p></blockquote><p>It's important to note that LLaMA isn't fully "open". You have to agree to <a href="https://forms.gle/jk851eBVbX1m5TAv5">some strict terms</a> to access the model. It's intended as a research preview, and isn't something which can be used for commercial purposes.</p><p>In a totally cyberpunk move, within a few days of the release, someone <a href="https://github.com/facebookresearch/llama/pull/73">submitted this PR</a> to the LLaMA repository linking to an unofficial BitTorrent download link for the model files!</p><p>So they're in the wild now. You may not be legally able to build a commercial product on them, but the genie is out of the bottle. That furious typing sound you can hear is thousands of hackers around the world starting to dig in and figure out what life is like when you can run a GPT-3 class model on your own hardware.</p><h4>llama.cpp</h4><p>LLaMA on its own isn't much good if it's still too hard to run it on a personal laptop.</p><p>Enter <a href="https://ggerganov.com/">Georgi Gerganov</a>.</p><p>Georgi is an open source developer based in Sofia, Bulgaria (according to <a href="https://github.com/ggerganov">his GitHub profile</a>). He previously released <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a>, a port of OpenAI's Whisper automatic speech recognition model to C++. That project made Whisper applicable to a huge range of new use cases.</p><p>He's just done the same thing with LLaMA.</p><p>Georgi's <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> project had its <a href="https://github.com/ggerganov/llama.cpp/commit/26c084662903ddaca19bef982831bfb0856e8257">initial release yesterday</a>. From the README:</p><blockquote><p>The main goal is to run the model using 4-bit quantization on a MacBook.</p></blockquote><p>4-bit quantization is a technique for reducing the size of models so they can run on less powerful hardware. It also reduces the model sizes on disk - to 4GB for the 7B model and just under 8GB for the 13B one.</p><p>It totally works!</p><p>I used it to run the 7B LLaMA model on my laptop this night, and then this morning upgraded to the 13B model - the one that Facebook claim is competitive with GPT-3.</p><p>Here are my <a href="https://til.simonwillison.net/llms/llama-7b-m2">detailed notes on how I did that</a> - most of the information I needed was already there in the README.</p><p>As my laptop started to spit out text at me I genuinely had a feeling that the world was about to change, again.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif" width="1016" height="501" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:501,&quot;width&quot;:1016,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Animated GIF showing LLaMA on my laptop completing a prompt about The first man on the moon was - it only takes a few seconds to complete and outputs information about Neil Armstrong&quot;,&quot;title&quot;:&quot;Animated GIF showing LLaMA on my laptop completing a prompt about The first man on the moon was - it only takes a few seconds to complete and outputs information about Neil Armstrong&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Animated GIF showing LLaMA on my laptop completing a prompt about The first man on the moon was - it only takes a few seconds to complete and outputs information about Neil Armstrong" title="Animated GIF showing LLaMA on my laptop completing a prompt about The first man on the moon was - it only takes a few seconds to complete and outputs information about Neil Armstrong" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98838d9d-0f1a-4533-982c-ad27c6f33458_1016x501.gif 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>I thought it would be a few more years before I could run a GPT-3 class model on hardware that I owned. I was wrong: that future is here already.</p><h4>Is this the worst thing that ever happened?</h4><p>I'm not worried about the science fiction scenarios here. The language model running on my laptop is not an AGI that's going to <a href="https://en.wikipedia.org/wiki/The_Mitchells_vs._the_Machines">break free and take over the world</a>.</p><p>But there are a ton of very real ways in which this technology can be used for harm. Just a few:</p><ul><li><p>Generating spam</p></li><li><p>Automated romance scams</p></li><li><p>Trolling and hate speech</p></li><li><p>Fake news and disinformation</p></li><li><p>Automated radicalization (I worry about this one a lot)</p></li></ul><p>Not to mention that this technology makes things up exactly as easily as it parrots factual information, and provides no way to tell the difference.</p><p>Prior to this moment, a thin layer of defence existed in terms of companies like OpenAI having a limited ability to control how people interacted with those models.</p><p>Now that we can run these on our own hardware, even those controls are gone.</p><h4>How do we use this for good?</h4><p>I think this is going to have a huge impact on society. My priority is trying to direct that impact in a positive direction.</p><p>It's easy to fall into a cynical trap of thinking there's nothing good here at all, and everything generative AI is either actively harmful or a waste of time.</p><p>I'm personally using generative AI tools on a daily basis now for a variety of different purposes. They've given me a material productivity boost, but more importantly they have expanded my ambitions in terms of projects that I take on.</p><p>I used ChatGPT to learn enough AppleScript to ship a new project in <a href="https://til.simonwillison.net/gpt3/chatgpt-applescript">less than an hour</a> just last week!</p><p>I'm going to continue exploring and sharing genuinely positive applications of this technology. It's not going to be un-invented, so I think our priority should be figuring out the most constructive possible ways to use it.</p><h4>What to look for next</h4><p>Assuming Facebook don't relax the licensing terms, LLaMA will likely end up more a proof-of-concept that local language models are feasible on consumer hardware than a new foundation model that people use going forward.</p><p>The race is on to release the first fully open language model that gives people ChatGPT-like capabilities on their own devices.</p><p>Quoting Stable Diffusion backer <a href="https://twitter.com/EMostaque/status/1634653313089126403">Emad Mostaque</a>:</p><blockquote><p>Wouldn't be nice if there was a fully open version eh</p></blockquote><h4>It's happening already...</h4><p>I published this article on Saturday 11th March 2023. On Sunday, Artem Andreenko got it running on a RaspberryPi with 4GB of RAM:</p><blockquote><p>I've sucefully runned LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware. <a href="https://t.co/XDbvM2U5GY">pic.twitter.com/XDbvM2U5GY</a></p><p>- Artem Andreenko &#127482;&#127462; (@miolini) <a href="https://twitter.com/miolini/status/1634982361757790209?ref_src=twsrc%5Etfw">March 12, 2023</a></p></blockquote><p>Then on Monday, Anish Thite got it working on a Pixel 6 phone (at 26s/token):</p><blockquote><p><a href="https://twitter.com/ggerganov?ref_src=twsrc%5Etfw">@ggerganov</a>'s LLaMA works on a Pixel 6!<br><br>LLaMAs been waiting for this, and so have I <a href="https://t.co/JjEhdzJ2B9">pic.twitter.com/JjEhdzJ2B9</a></p><p>- anishmaxxing (@thiteanish) <a href="https://twitter.com/thiteanish/status/1635188333705043969?ref_src=twsrc%5Etfw">March 13, 2023</a></p></blockquote><h3><a href="https://simonwillison.net/2023/Mar/13/alpaca/">Stanford Alpaca, and the acceleration of on-device large language model development</a> - 2023-03-13</h3><p>On Saturday 11th March I wrote about how <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their Stable Diffusion moment</a>. Today is Monday. Let's look at what's happened in the past three days.</p><ul><li><p>Later on Saturday: Artem Andreenko reports that <code>llama.cpp</code> can <a href="https://twitter.com/miolini/status/1634982361757790209">run the 4-bit quantized 7B LLaMA language model model on a 4GB RaspberryPi</a> - at 10 seconds per token, but still hugely impressive.</p></li><li><p>Sunday 12th March: <a href="https://twitter.com/cocktailpeanut">cocktailpeanut</a> releases <a href="https://cocktailpeanut.github.io/dalai/">Dalai</a>, a "dead simple way to run LLaMA on your computer": <code>npx dalai llama</code> and <code>npx dalai serve</code>.</p></li><li><p>13th March (today): Anish Thite reports <code>llama.cpp</code> running <a href="https://twitter.com/thiteanish/status/1635188333705043969">on a Pixel 6 phone</a> (26 seconds per token).</p></li><li><p>Also today: a team at Stanford released <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong Open-Source Instruction-Following Model</a> - fine-tuned from the LLaMA 7B model.</p></li></ul><p>When I talked about a "Stable Diffusion moment" this is the kind of thing I meant: the moment this stuff is available for people to experiment with, things accelerate.</p><p>I'm going to dive into Alpaca in detail.</p><h4>Stanford's Alpaca</h4><p>Here's the introduction to <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">the Alpaca announcement</a>:</p><blockquote><p>We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. Alpaca behaves similarly to OpenAI&#8217;s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$).</p></blockquote><p>The biggest weakness in the LLaMA models released by Meta research last month is their lack of instruction-tuning.</p><p>A language model is a sentence completion engine. You give it a sequence of words, "The first man on the moon was", and it completes that sentence, hopefully with useful content.</p><p>One of the great innovations from OpenAI was their application of <a href="https://openai.com/research/instruction-following">instruction tuning</a> to GPT-3:</p><blockquote><p>To make our models safer, more helpful, and more aligned, we use an existing technique called reinforcement learning from human feedback (RLHF). On prompts submitted by our customers to the API, our labelers provide demonstrations of the desired model behavior, and rank several outputs from our models. We then use this data to fine-tune GPT-3.</p></blockquote><p>Prior to this, you had to think very carefully about how to construct your prompts. Thanks to instruction tuning you can be a lot more, well, human in the way you interact with the model. "Write me a poem about pandas!" now works as a prompt, instead of "Here is a poem about pandas:".</p><p>The LLaMA models had not been through this process. The <a href="https://github.com/facebookresearch/llama/blob/57b0eb62de0636e75af471e49e2f1862d908d9d8/FAQ.md#2-generations-are-bad">LLaMA FAQ</a> acknowledges this:</p><blockquote><p>Keep in mind these models are not finetuned for question answering. As such, they should be prompted so that the expected answer is the natural continuation of the prompt. [...] Overall, always keep in mind that models are very sensitive to prompts (particularly when they have not been finetuned).</p></blockquote><p>This is an enormous usability problem.</p><p>One of my open questions about LLaMA was how difficult and expensive it would be to fine-tune it such that it could respond better to instructions.</p><p>Thanks to the team at Stanford we now have an answer: 52,000 training samples and $600 of training compute!</p><p>Something that stuns me about Alpaca is the quality they claim to be able to get from the 7B model - the smallest of the LLaMA models, and the one which has been seen running (albeit glacially slowly) on a RaspberryPi and a mobile phone! Here's one example from their announcement:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png" width="1456" height="745" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:745,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Enter your instruction and press enter: Write an e-mail to congratulate new Stanford admits and mention that you are exited about meeting all of them in person Stanford-Alpaca-7B: An Open-Source Instruction-Following Language Model Dear Stanford Admits, Congratulations on your admission to Stanford! I am so excited to meet all of you in person. As a current student at Stanford, I am looking forward to welcoming you to the Stanford community and showing you all that the university has to offer. I wish you all the best in your future endeavors and I can't wait to see you on campus! Sincerely, Your Name&quot;,&quot;title&quot;:&quot;Enter your instruction and press enter: Write an e-mail to congratulate new Stanford admits and mention that you are exited about meeting all of them in person Stanford-Alpaca-7B: An Open-Source Instruction-Following Language Model Dear Stanford Admits, Congratulations on your admission to Stanford! I am so excited to meet all of you in person. As a current student at Stanford, I am looking forward to welcoming you to the Stanford community and showing you all that the university has to offer. I wish you all the best in your future endeavors and I can't wait to see you on campus! Sincerely, Your Name&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Enter your instruction and press enter: Write an e-mail to congratulate new Stanford admits and mention that you are exited about meeting all of them in person Stanford-Alpaca-7B: An Open-Source Instruction-Following Language Model Dear Stanford Admits, Congratulations on your admission to Stanford! I am so excited to meet all of you in person. As a current student at Stanford, I am looking forward to welcoming you to the Stanford community and showing you all that the university has to offer. I wish you all the best in your future endeavors and I can't wait to see you on campus! Sincerely, Your Name" title="Enter your instruction and press enter: Write an e-mail to congratulate new Stanford admits and mention that you are exited about meeting all of them in person Stanford-Alpaca-7B: An Open-Source Instruction-Following Language Model Dear Stanford Admits, Congratulations on your admission to Stanford! I am so excited to meet all of you in person. As a current student at Stanford, I am looking forward to welcoming you to the Stanford community and showing you all that the university has to offer. I wish you all the best in your future endeavors and I can't wait to see you on campus! Sincerely, Your Name" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F448e2c3a-d9d0-4e2a-ae7f-d134277d7262_2968x1518.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><p>I would be impressed to see this from the 65B (largest) LLaMA model - but getting this from 7B is spectacular.</p><h4>Still not for commercial usage</h4><p>I'll quote the Stanford announcement on this in full:</p><blockquote><p>We emphasize that Alpaca is intended <strong>only for academic research</strong> and any <strong>commercial use is prohibited</strong>. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial <a href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform">license</a>, so we necessarily inherit this decision. Second, the instruction data is based OpenAI's text-davinci-003, whose <a href="https://openai.com/policies/terms-of-use">terms of use</a> prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use.</p></blockquote><p>So it's still not something we can use to build commercial offerings - but for personal research and tinkering it's yet another huge leap forwards.</p><h4>What does this demonstrate?</h4><p>The license of the LLaMA model doesn't bother me too much. What's exciting to me is what this all proves.</p><ul><li><p>LLaMA itself shows that it's possible to train a GPT-3 class language model using openly available resources. The <a href="https://arxiv.org/abs/2302.13971">LLaMA paper</a> includes details of the training data, which is entirely from publicly available sources (which include CommonCrawl, GitHub, Wikipedia, ArXiv and ArXiv).</p></li><li><p><code>llama.cpp</code> shows that you can then use some tricks run that language model on consumer hardware - apparently anything with 4GB or more of RAM is enough to at least get it to start spitting out tokens!</p></li><li><p>Alpaca shows that you can apply fine-tuning with a feasible sized set of examples (52,000) and cost ($600) such that even the smallest of the LLaMA models - the 7B one, which can compress down to a 4GB file with 4-bit quantization - provides results that compare well to cutting edge <code>text-davinci-003</code> in initial human evaluation.</p></li></ul><p>One thing that's worth noting: the Alpaca 7Bb comparison likely used the full-sized 13.48GB 16bit floating point 7B model, not the 4GB smaller 4bit floating point model used by <code>llama.cpp</code>. I've not yet seen a robust comparison of quality between the two.</p><h4>Exploring the Alpaca training data with Datasette Lite</h4><p>The Alpaca team released the 52,000 fine-tuning instructions they used as <a href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json">a 21.7MB JSON file</a> in their GitHub repository.</p><p>My <a href="https://simonwillison.net/2022/May/4/datasette-lite/">Datasette Lite</a> tool has the ability to fetch JSON from GitHub and load it into an in-browser SQLite database. Here's the URL to do that:</p><p><a href="https://lite.datasette.io/?json=https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json">https://lite.datasette.io/?json=https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json</a></p><p>This will let you browse the 52,000 examples in your browser.</p><p>But we can do a step better than that: here's a SQL query that runs LIKE queries to search through those examples, considering all three text columns:</p><pre><code><code>select instruction, input, output from alpaca_data
where instruction || ' ' || input || ' ' || output like '%' || :search || '%'
order by random()</code></code></pre><p>I'm using <code>order by random()</code> because why not? It's more fun to explore that way.</p><p>The following link will both load the JSON file and populate and execute that SQL query, plus allow you to change the search term using a form in your browser:</p><p><a href="https://lite.datasette.io/?json=https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json#/data?sql=select+instruction%2C+input%2C+output+from+alpaca_data%0Awhere+instruction+%7C%7C+%27+%27+%7C%7C+input+%7C%7C+%27+%27+%7C%7C+output+like+%27%25%27+%7C%7C+%3Asearch+%7C%7C+%27%25%27%0Aorder+by+random%28%29&amp;search=occam">https://lite.datasette.io/?json=https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json#/data?sql=select+instruction%2C+input%2C+output+from+alpaca_data%0Awhere+instruction+%7C%7C+%27+%27+%7C%7C+input+%7C%7C+%27+%27+%7C%7C+output+like+%27%25%27+%7C%7C+%3Asearch+%7C%7C+%27%25%27%0Aorder+by+random%28%29&amp;search=occam</a></p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg" width="1456" height="941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Screenshot of Datasette executing that SQL query, retruning three results that match 'occam'&quot;,&quot;title&quot;:&quot;Screenshot of Datasette executing that SQL query, retruning three results that match 'occam'&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Screenshot of Datasette executing that SQL query, retruning three results that match 'occam'" title="Screenshot of Datasette executing that SQL query, retruning three results that match 'occam'" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4113dcdf-c1bc-4a98-9076-64013f7ab461_2580x1668.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a></figure></div><h4>What's next?</h4><p>This week is likely to be wild. OpenAI are rumored to have a big announcement on Tuesday - possibly GPT-4? And I've heard rumors of announcements from both Anthropic and Google this week as well.</p><p>I'm still more excited about seeing what happens next with LLaMA. Language models on personal devices is happening so much faster than I thought it would.</p><div><hr></div><p><strong>Link</strong> 2023-03-08 <a href="https://discord.com/blog/how-discord-stores-trillions-of-messages">How Discord Stores Trillions of Messages</a>: This is a really interesting case-study. Discord migrated from MongoDB to Cassandra back in 2016 to handle billions of messages. Today they're handling trillions, and they completed a migration from Cassandra to Scylla, a Cassandra-like data store written in C++ (as opposed to Cassandra's Java) to help avoid problems like GC pauses. In addition to being a really good scaling war story this has some interesting details about their increased usage of Rust. As a fan of request coalescing (which I've previously referred to as dogpile prevention) I particularly liked this bit: "Our data services sit between the API and our ScyllaDB clusters. They contain roughly one gRPC endpoint per database query and intentionally contain no business logic. The big feature our data services provide is request coalescing. If multiple users are requesting the same row at the same time, we&#8217;ll only query the database once. The first user that makes a request causes a worker task to spin up in the service. Subsequent requests will check for the existence of that task and subscribe to it. That worker task will query the database and return the row to all subscribers."</p><div><hr></div><p><strong>Link</strong> 2023-03-09 <a href="https://github.com/dogsheep/apple-notes-to-sqlite">apple-notes-to-sqlite</a>: With the help of ChatGPT I finally figured out just enough AppleScript to automate the export of my notes to a SQLite database. AppleScript is a notoriously read-only language, which is turns out makes it a killer app for LLM-assisted coding.</p><div><hr></div><p><strong>Quote</strong> 2023-03-10</p><blockquote><p><em>What could I&nbsp;do with a universal function&#8202;&#8212;&#8202;a tool for turning just about any X into just about any Y with plain language instructions?</em></p></blockquote><p><a href="https://www.robinsloan.com/lab/phase-change/">Robin Sloan</a></p><div><hr></div><p><strong>Link</strong> 2023-03-11 <a href="https://til.simonwillison.net/llms/llama-7b-m2">Running LLaMA 7B on a 64GB M2 MacBook Pro with llama.cpp</a>: I got Facebook's LLaMA 7B to run on my MacBook Pro using llama.cpp (a "port of Facebook's LLaMA model in C/C++") by Georgi Gerganov. It works! I've been hoping to run a GPT-3 class language model on my own hardware for ages, and now it's possible to do exactly that. The model itself ends up being just 4GB after applying Georgi's script to "quantize the model to 4-bits".</p><div><hr></div><p><strong>Link</strong> 2023-03-07 <a href="https://maxhalford.github.io/blog/ogd-in-sql/">Online gradient descent written in SQL</a>: Max Halford trains an online gradient descent model against two years of AAPL stock data using just a single advanced SQL query. He built this against DuckDB - I tried to replicate his query in SQLite and it almost worked, but it gave me a "recursive reference in a subquery" error that I was unable to resolve.</p><div><hr></div><h3><a href="https://simonwillison.net/2023/Mar/7/kqed-forum/">Weeknotes: NICAR, and an appearance on KQED Forum</a> - 2023-03-07</h3><p>I spent most of this week <a href="https://www.ire.org/training/conferences/nicar-2023/">at NICAR 2023</a>, the data journalism conference hosted this year in Nashville, Tennessee.</p><p>This was my third in-person NICAR and it's an absolute delight: NICAR is one of my favourite conferences to go to. It brings together around a thousand journalists who work with data, from all over the country and quite a few from the rest of the world.</p><p>People have very different backgrounds and experiences, but everyone has one thing in common: a nerdy obsession with using data to find and tell stories.</p><p>I came away with at least a year's worth of new ideas for things I want to build.</p><p>I also presented a session: an hour long workshop titled "Datasette: An ecosystem of tools for exploring data and collaborating on data projects".</p><p>I demonstrated the scope of the project, took people through some hands-on exercises derived from the Datasette tutorials <a href="https://datasette.io/tutorials/clean-data">Cleaning data with sqlite-utils and Datasette</a> and <a href="https://datasette.io/tutorials/codespaces">Using Datasette in GitHub Codespaces</a> and invited everyone in the room to join the <a href="https://datasette.cloud/">Datastte Cloud</a> preview and try using <a href="https://datasette.io/plugins/datasette-socrata">datasette-socrata</a> to import and explore some data from the <a href="https://data.sfgov.org/">San Francisco open data portal</a>.</p><p>My goal for this year's NICAR was to setup some direct collaborations with working newsrooms. Datasette is ready for this now, and I'm willing to invest significant time and effort in onboarding newsrooms, helping them start using the tools and learning what I need to do to help them be more effective in that environment.</p><p>If your newsroom is interested in that, please drop me an email at <code>swillison@</code> Google's email service.</p><h4>KQED Forum</h4><p>My <a href="https://simonwillison.net/2023/Feb/15/bing/">post about Bing</a> attracted attention from the production team at <a href="https://www.kqed.org/forum">KQED Forum</a>, a long-running and influential Bay Area news discussion radio show.</p><p>They invited me to join a live panel discussion on Thursday morning with science-fiction author Ted Chiang and Claire Leibowitz from Partnership on AI.</p><p>I've never done live radio before, so this was an opportunity that was too exciting to miss. I ducked out of the conference for an hour to join the conversation via Zoom.</p><p>Aside from a call with a producer a few days earlier I didn't have much of an idea what to expect (similar to my shorter <a href="https://simonwillison.net/2023/Feb/19/live-tv/">live TV appearance</a>). You really have to be able to think on your feet!</p><p>A recording is available <a href="https://www.kqed.org/forum/2010101892368/how-to-wrap-our-heads-around-these-new-shockingly-fluent-chatbots">on the KQED site</a>, and <a href="https://podcasts.apple.com/us/podcast/kqeds-forum/id73329719?i=1000602544514">on Apple Podcasts</a>.</p><p>I'm happy with most of it, but I did have one offensive and embarassing slip-up. I was talking about <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html">the Kevin Roose ChatGPT conversation from the New York Times</a>, where Bing declared its love for him. I said (05:30):</p><blockquote><p>So I love this particular example because it actually accidentally illustrates exactly how these things work.</p><p>All of these chatbots, all of these language models they're called, all they can do is predict sentences.</p><p>They predict the next word that statistically makes sense given what's come before.</p><p>And if you look at the way it talks to Kevin Roose, I've got a quote.</p><p>It says, "You're married, but you're not happy. You're married, but you're not satisfied. You're married, but you're not in love."</p><p>No human being would talk like that. That's practically a kind of weird poetry, right?</p><p>But if you're thinking about in terms of, OK, what sentence should logically come after this sentence?</p><p>"You're not happy, and then you're not satisfied", and then "you're not in love" - those just work. So Kevin managed to get himself into the situation where this bot was way off the reservation.</p><p>This is one of the most monumental software bugs of all time.</p><p>This was Microsoft's Bing search engine. They had a bug in their search engine where it would try and get a user to break up with their wife!</p><p>That's absolutely absurd.</p><p>But really, all it's doing is it had got itself to a point in the conversation where it's like, Okay, well, I'm in the mode of trying to talk about how why a marriage isn't working?</p><p>What comes next? What comes next? What comes next?</p></blockquote><p>In talking about Bing's behaviour I've been trying to avoid words like "crazy" and "psycho", because those stigmatize mental illness. I try to use terms like "wild" and "inappropriate" and "absurd" instead.</p><p>But saying something is "off the reservation" is much worse!</p><p>The term <a href="https://www.npr.org/sections/codeswitch/2014/06/29/326690947/should-saying-someone-is-off-the-reservation-be-off-limits">is deeply offensive</a>, based on a dark history of forced relocation of Native Americans. I used it here thoughtlessly. If you asked me to think for a moment about whether it was an appropriate phrase I would have identified that it wasn't. I'm really sorry to have said this, and I will be avoiding this language in the future.</p><p>I'll share a few more annotated highlights from the transcript, thankfully without any more offensive language.</p><p>Here's my response to a question about how I've developed my own understanding of how these models actually work (19:47):</p><blockquote><p>I'm a software engineer. So I've played around with training my own models on my laptop. I found an example where you can <a href="https://til.simonwillison.net/llms/nanogpt-shakespeare-m2">train one just on the complete works of Shakespeare</a> and then have it spit out garbage Shakespeare, which has "thee" and "thus" and so forth.</p><p>And it looks like Shakespeare until you read a whole sentence and you realize it's total nonsense.</p><p><a href="https://til.simonwillison.net/llms/training-nanogpt-on-my-blog">I did the same thing with my blog</a>. I've got like 20 years of writing that I piped into it and it started producing sentences which were clearly in my tone even though they meant nothing.</p><p>It's so interesting seeing it generate these sequences of words in kind of a style but with no actual meaning to them.</p><p>And really that's exactly the same thing as ChatGPT. It's just that ChatGPT was fed terabytes of data and trained for months and months and months, whereas I fed in a few megabytes of data and trained it for 15 minutes.</p><p>So that really helps me start to get a feel for how these things work. The most interesting thing about these models is it turns out there's this sort of inflection point in size where you train them and they don't really get better up until a certain point where suddenly they start gaining these capabilities.</p><p>They start being able to summarize text and generate poems and extract things into bullet pointed lists. And the impression I've got from the AI research community is people aren't entirely sure that they understand why that happens at a certain point.</p><p>A lot of AI research these days is just, let's build it bigger and bigger and bigger and play around with it. And oh look, now it can do this thing. <a href="https://twitter.com/zswitten/status/1631107663500304384">I just saw this morning that someone's got it playing chess</a>. It shouldn't be able to play chess, but it turns out the Bing one can play chess and like nine out of ten of the moves it generates are valid moves and one out of ten are rubbish because it doesn't have a chess model baked into it.</p><p>So this is one of the great mysteries of these things, is that as you train them more, they gain these capabilities that no one was quite expecting them to gain.</p><p>Another example of that: these models are really good at writing code, like writing actual code for software, and nobody really expected that to be the case, right? They weren't designed as things that would replace programmers, but actually the results you can get out of them if you know how how to use them in terms of generating code can be really sophisticated.</p><p>One of the most important lessons I think is that these things are actually deceptively difficult to use, right? It's a chatbot. How hard can it be? You just type things and it says things back to you.</p><p>But if you want to use it effectively, you have to understand pretty deeply what its capabilities and limitations are. If you try and give it mathematical puzzles, it will fail miserably because despite being a computer - and computers should be good at maths! - that's not something that language models are designed to handle.</p><p>And it'll make things up left, right, and center, which is something you need to figure out pretty quickly. Otherwise, you're gonna start believing just garbage that it throws out at you.</p><p>So there's actually a lot of depth to this. I think it's worth investing a lot of time just playing games with these things and trying out different stuff, because it's very easy to use them incorrectly. And there's very little guidance out there about what they're good at and what they're bad at. It takes a lot of learning.</p></blockquote><p>I was happy with my comparison of writing cliches to programming. A caller had mentioned that they had seen it produce an answer to a coding question that invented an API that didn't exist, causing them to lose trust in it as a programming tool (23:11):</p><blockquote><p>I can push back slightly on this example. That's absolutely right. It will often invent API methods that don't exist. But as somebody who creates APIs, I find that really useful because sometimes it invents an API that doesn't exist, and I'll be like, well, that's actually a good idea.</p><p>Because the thing it's really good at is consistency. And when you're designing APIs, consistency is what you're aiming for. So, you know, in writing, you want to avoid cliches. In programming, cliches are your friend. So, yeah, I actually use it as a design assistant where it'll invent something that doesn't exist. And I'll be like, okay, well, maybe that's the thing that I should build next.</p></blockquote><p>A caller asked "Are human beings not also statistically created language models?". My answer to that (at 35:40):</p><blockquote><p>So I'm not a neurologist, so I'm not qualified to answer this question in depth, but this does come up a lot in AI circles. In the discourse, yeah.</p><p>Yes, so my personal feeling on this is there is a very small part of our brain that kind of maybe works a little bit like a language model. You know, when you're talking, it's pretty natural to think what word's going to come next in that sentence.</p><p>But I'm very confident that that's only a small fraction of how our brains actually work. When you look at these language models like ChatGPT today, it's very clear that if you want to reach this mythical AGI, this general intelligence, it's going to have to be a heck of a lot more than just a language model, right?</p><p>You need to tack on models that can tell truth from fiction and that can do sophisticated planning and do logical analysis and so forth. So yeah, my take on this is, sure, there might be a very small part of how our brains work that looks a little bit like a language model if you squint at it, but I think there's a huge amount more to cognition than just the tricks that these language models are doing.</p></blockquote><p>These transcripts were all edited together from an initial attempt created using OpenAI Whisper, running directly on my Mac using <a href="https://goodsnooze.gumroad.com/l/macwhisper">MacWhisper</a>.</p><h4>Releases this week</h4><ul><li><p><strong><a href="https://github.com/simonw/datasette-simple-html">datasette-simple-html</a></strong>: <a href="https://github.com/simonw/datasette-simple-html/releases/tag/0.1">0.1</a> - 2023-03-01 <br>Datasette SQL functions for very simple HTML operations</p></li><li><p><strong><a href="https://github.com/simonw/datasette-app">datasette-app</a></strong>: <a href="https://github.com/simonw/datasette-app/releases/tag/0.2.3">0.2.3</a> - (<a href="https://github.com/simonw/datasette-app/releases">5 releases total</a>) - 2023-02-27 <br>The Datasette macOS application</p></li></ul><h4>TIL this week</h4><ul><li><p><a href="https://til.simonwillison.net/gpt3/chatgpt-api">A simple Python wrapper for the ChatGPT API</a></p></li></ul><div><hr></div><div><hr></div><p><strong>Link</strong> 2023-03-11 <a href="https://minimaxir.com/2023/03/new-chatgpt-overlord/">ChatGPT's API is So Good and Cheap, It Makes Most Text Generating AI Obsolete</a>: Max Woolf on the quite frankly weird economics of the ChatGPT API: it's 1/10th the price of GPT-3 Da Vinci and appears to be equivalent (if not more) capable. "But it is very hard to economically justify not using ChatGPT as a starting point for a business need and migrating to a more bespoke infrastructure later as needed, and that&#8217;s what OpenAI is counting on. [...] I don&#8217;t envy startups whose primary business is text generation right now."</p><div><hr></div><p><strong>Quote</strong> 2023-03-12</p><blockquote><p><em>I've successfully run LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware.</em></p></blockquote><p><a href="https://twitter.com/miolini/status/1634982361757790209">Artem Andreenko</a></p><div><hr></div><p><strong>Quote</strong> 2023-03-13</p><blockquote><p><em>We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. Alpaca behaves similarly to OpenAI&#8217;s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$).</em></p></blockquote><p><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong Open-Source Instruction-Following Model</a></p><div><hr></div><div><hr></div><div class="subscription-widget-wrap" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;}"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading Simon Willison&#8217;s Newsletter! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div>]]></content:encoded>
    </item>
    <item>
      <title><![CDATA[Coming soon]]></title>
      <description><![CDATA[This is Simon Willison&#8217;s Newsletter, a newsletter about Web engineering, open source, data science, Datasette, SQLite, Python and more My blog: https://simonwillison.net/ - my TILs: https://til.simonwillison.net/]]></description>
      <link>https://simonw.substack.com/p/coming-soon</link>
      <guid isPermaLink="true">https://simonw.substack.com/p/coming-soon</guid>
      <dc:creator><![CDATA[Simon Willison]]></dc:creator>
      <pubDate>Fri, 04 Nov 2022 01:49:24 GMT</pubDate>
      <content:encoded><![CDATA[<p><strong>This is Simon Willison&#8217;s Newsletter</strong>, a newsletter about Web engineering, open source, data science, Datasette, SQLite, Python and more My blog: <a href="https://simonwillison.net/">https://simonwillison.net/</a> - my TILs: <a href="https://til.simonwillison.net/">https://til.simonwillison.net/</a></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://simonw.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}"><a class="button primary" href="https://simonw.substack.com/subscribe?"><span>Subscribe now</span></a></p>]]></content:encoded>
    </item>
  </channel>
</rss>

